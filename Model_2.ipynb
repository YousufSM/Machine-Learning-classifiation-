{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing XGBoost using Grid Search as well as Hyperopt\n",
    "- modeltype: **XGBoost** \n",
    "- train: **0.886**\n",
    "- test: **0.865**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow of the notebook\n",
    "* 0. Rationale behind choosing XGBoost\n",
    "* 1. Reading Data and importing libraries\n",
    "* 2. Data Manipulation\n",
    "* 3. Implementing XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Rationale behind choosing XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many articles online that has compared XGBoost, CatBoost and LightGBM and in most of them, XGBoost had a relatively lesser efficiency, and in few of them, it also had a relatively lesser accuracy.\n",
    "\n",
    "But after researching a bit, XGBoost seemed a highly popular algorithm in data scienstist community and also several top performing kagglers had mentioned this algorithm in the past. So even though being a bit older and relatively inefficient compared to CatBoost and LighGBM I was curious to get my hands on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have explained the working and parameter tuning of the algorithm in the section 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Data & Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data operations\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "# H20 and Grid Search\n",
    "import h2o\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "\n",
    "# Hyper Opt\n",
    "import hyperopt\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Uncomment this if the category_encoder version is less than 2.1.0\n",
    "# ! pip install category_encoders # This will update Sk-learn as well\n",
    "from category_encoders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Final_Project/Pcode\n"
     ]
    }
   ],
   "source": [
    "# Set directories\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData   = \"../PData/\"\n",
    "dirPOutput = \"../POutput/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = dirPData + '01_df_250k.pickle'\n",
    "\n",
    "with (open(f_name, \"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_train = dict_['df_train']\n",
    "df_test  = dict_['df_test']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = dirPData + '01_vars.pickle'\n",
    "\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "vars_ind_numeric     = dict_['vars_ind_numeric']\n",
    "vars_ind_hccv        = dict_['vars_ind_hccv']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "vars_notToUse        = ['unique_id']\n",
    "var_dep              = dict_['var_dep']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Treating NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Handling NAs**\n",
    "\n",
    "One of the advantage of XGBoost over other Gradient Boosting algorithm is it efficiently handles the missing values. As Tianqi Chen has discussed in his paper\n",
    "> When a value is missing in the sparse matrix x, the instance is classified into the default direction. There are two choices\n",
    "of default direction in each branch. The optimal default directions are learnt from the data. The key improvement is to only visit the non-missing entries. The presented algorithm treats the non-presence as a missing value and learns the best direction to handle missing values. \n",
    "\n",
    "And as mentioned in the H20 documentation: \n",
    ">  Missing values are interpreted as containing information (i.e., missing for a reason), rather than missing at random. During tree building, split decisions for every node are found by minimizing the loss function and treating missing values as a separate category that can go either left or right. XGBoost will automatically learn which is the best direction to go when a value is missing.\n",
    "\n",
    "Following this, we have decided not to do any operations on missing value (except for deleting 'c02' column becuase it contain >50% of missing values in test data). \n",
    "\n",
    "-99 values will be treated in the H20 Frame, right now we are only removing 'C02' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Since C02 has a lot of NAs (>50%), we will drop it from both train and test\n",
    "df_test.drop('c02', axis=1, inplace = True)\n",
    "df_train.drop('c02', axis=1, inplace = True)\n",
    "vars_ind_categorical.remove('c02')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cardinality\n",
    "   For treating the hccv we have used Target Encoders (Sk-Learn). We have also observed that there is oversampling of few factors \n",
    "    while others are under-sampled therefore we have used smoothing factor = 4. Smoothing of 4 is chosen by following few online \n",
    "    blogs. Also scikit learn is used to do the target encoding because I was a bit confused with H20 target encoding. Additionally,\n",
    "    H20 automatically perform one_hot encoding on categorical variables so they have not been treated.\n",
    "\n",
    "\n",
    "Note: I needed to update the scikit-learn and category_ecoders library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the distribution of factors in a hcc variable\n",
    "# df_train[vars_ind_hccv].nunique()\n",
    "# df_train['e18'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target encoders on Train\n",
    "enc = TargetEncoder(cols=vars_ind_hccv, smoothing =4)\n",
    "enc.fit_transform(df_train, df_train['target'])\n",
    "df_train = enc.transform(df_train, df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target encoders on Test\n",
    "df_test['target'] = np.nan # Creating dummy 'target' variable for using the the enc.transform function\n",
    "df_test = enc.transform(df_test) # applying the already trained encoder\n",
    "df_test.drop(columns=['target'], inplace=True) # Dropping dummy 'target' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running H20 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shutdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8ae2ce013486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shutdown'"
     ]
    }
   ],
   "source": [
    "# h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_212\"; OpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-0ubuntu1.18.04.1-b03); OpenJDK 64-Bit Server VM (build 25.212-b03, mixed mode)\n",
      "  Starting server from /opt/conda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp17mtc_0v\n",
      "  JVM stdout: /tmp/tmp17mtc_0v/h2o_jovyan_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp17mtc_0v/h2o_jovyan_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
      "Warning: Your H2O cluster version is too old (1 year, 2 months and 8 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 year, 2 months and 8 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_jovyan_s0rtq1</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>12.44 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.7 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.3\n",
       "H2O cluster version age:    1 year, 2 months and 8 days !!!\n",
       "H2O cluster name:           H2O_from_python_jovyan_s0rtq1\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    12.44 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.7 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://localhost:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 year, 2 months and 8 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_jovyan_s0rtq1</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>12.44 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.7 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.3\n",
       "H2O cluster version age:    1 year, 2 months and 8 days !!!\n",
       "H2O cluster name:           H2O_from_python_jovyan_s0rtq1\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    12.44 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.7 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<H2OConnection to http://localhost:54321, no session>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.init(port=54321, max_mem_size = \"14g\") # Asking h20 to use 14 GB of Ram\n",
    "h2o.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have removed 'unique_id' from Frames as it was not useful in prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "vars_to_use = vars_ind_numeric + vars_ind_categorical\n",
    "vars_to_use.remove('unique_id')\n",
    "vars_ind_numeric.remove('unique_id')\n",
    "\n",
    "\n",
    "h2o_df_train = h2o.H2OFrame(df_train[[var for var in vars_to_use+var_dep ]], destination_frame = 'df_train') # Train Frame\n",
    "h2o_df_test  = h2o.H2OFrame(df_test[[var for var in vars_to_use]], destination_frame = 'df_test') # Test Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting -99 to NAs. We have not done this before becuase as discussed earlier, converting pandas NAs to H20 Frame were not consistent and was giving an error (may be due to the older version of H20 in the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting -99 to NA in train\n",
    "for var in vars_ind_numeric:\n",
    "    h2o_df_train[h2o_df_train[var] == -99.0 , var] = None\n",
    "    \n",
    "# Converting -99 to NA in test\n",
    "for var in vars_ind_numeric:\n",
    "    h2o_df_test[h2o_df_test[var] == -99.0 , var] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H20 Document suggest to make dependant variable as factor for classiication task\n",
    "h2o_df_train[var_dep] = h2o_df_train[var_dep].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Interactions\n",
    "Documentation regarding the interaction in XGBoost was not clear, therefore after  searching for online, especially [here](https://www.kaggle.com/c/bosch-production-line-performance/discussion/24418) making interaction seemed to be a logical choice given it has drastically improved the past model (GLM) performance.\n",
    "\n",
    "I have not used the interaction on all variables, instead I have used it only on 2 variables ('f03' and 'e11'). These two \n",
    "variables have been chosen after running GLM model and then calculating variables importance.\n",
    "I did not use all categorical variables, as it could not improve the performance significantly but made the\n",
    "model quite complex to comprehend. Therefore, it was a trade-off between accuracy and complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e20' has levels not trained on: [30146, BE271, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e13' has levels not trained on: [Q, S]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e24' has levels not trained on: [J, M, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e03' has levels not trained on: [J, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'c09' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'a18' has levels not trained on: [D]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['f10', 'f03.F', 'e19', 'e11.A', 'f03.E']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for runing GLM to see which all variables are important\n",
    "\n",
    "# Idea has been taken from: https://aichamp.wordpress.com/2017/09/29/python-example-of-building-glm-gbm-and-random-forest-\n",
    "# binomial-model-with-h2o/\n",
    "\n",
    "\n",
    "# from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "# glm_logistic = H2OGeneralizedLinearEstimator(family = \"binomial\")\n",
    "# glm_logistic.train(x=vars_to_use , y= 'target', training_frame=h2o_df_train, model_id=\"glm_logistic\")\n",
    "# preds = glm_logistic.predict(h2o_df_test)\n",
    "# df_test['Predicted'] = np.round(preds[2].as_data_frame(), 5)\n",
    "# df_preds_dt = df_test[['unique_id', 'Predicted']].copy()\n",
    "# df_test[['unique_id', 'Predicted']].to_csv(dirPOutput + '1st.csv', index=False)\n",
    "# log_var_imp = glm_logistic.varimp(use_pandas=True).head()\n",
    "# log_var_imp.loc[0:5, 'variable'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen min_occurence as int(len(h2o_df_train)/40) after many trial and error.\n",
    "\n",
    "With int(len(h2o_df_train)/40) on 250K train data I was getting 5 factors for each variable. I believe performing \n",
    "interactions on top 4-5 variables rather than all the variables having occurrence > 10/20 would make the model\n",
    "faster and more interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train Frame\n",
    "interaction_frame_train = h2o_df_train.interaction(['f03', 'e11'], pairwise = False, max_factors = 100,\n",
    "                                                   min_occurrence = int(len(h2o_df_train)/40))\n",
    "\n",
    "# Test Frame\n",
    "interaction_frame_test = h2o_df_test.interaction(['f03', 'e11'], pairwise = False, max_factors = 100, \n",
    "                                                 min_occurrence = int(len(h2o_df_train)/40))\n",
    "\n",
    "# Cbinding interaction frame to train and test\n",
    "h2o_df_train = h2o_df_train.cbind(interaction_frame_train)\n",
    "h2o_df_test = h2o_df_test.cbind(interaction_frame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incuding interaction frame's variable to variables list\n",
    "vars_to_use = vars_to_use + ['f03_e11']\n",
    "vars_ind_numeric = vars_ind_numeric + ['f03_e11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing XGBoost\n",
    "* **My understanding of the algorithm**\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is a boosting algorithm. Boosting refers to ensemble technique where several models (tree models) are being used to make the final model.\n",
    "\n",
    "Boosting models are build sequentially by minimising the errors from the previous model and Gradient Boosting is an advance version of boosting where the algorithm employs gradient descent method to minimise the error. The main difference between Bagging and Boosting is, Bagging combines different models while Boosting use the previous model to make a new model with less errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **One_hot encoding**\n",
    "\n",
    "Since XGBoost is dependent on Tree based algorithm, it was safe to assume that XGBoost do not require one_hot encoding. But after going through the paper [Chen T.,Guestrin C., XGBoost: A Scalable Tree Boosting System](https://arxiv.org/pdf/1603.02754.pdf) I realised that one_hot encoding is important if there are categorical variables to make XGBoost perfom better. \n",
    "\n",
    "After Going through H20 documentation, I realised that the algorithm, similar to GLM, automatically performs one_hot encoding for XGBoost and thus we do not have to manually do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Spline**\n",
    "\n",
    "Since XGBoost is based on Tree based algorithm, we have not used splines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 **Grid Search Vs HyperOpt**\n",
    "\n",
    "For my own understanding, I tried both, Grid Search and HyperOpt.\n",
    "\n",
    "Grid search processed only 2 algorithm in 2 hours optimising 5 hyper-parameters with 5 nfolds. It's Train AUC was = 0.889 and valid AUC = 0.879. Prediction accuracy on Kaggle for Grid Search algorithm was 0.865.\n",
    "\n",
    "On the other hand, HyperOpt explored 10 algorithms in 5 hours minutes (limit of 30 mins per algorithm) and returned train AUC of 0.886, validation AUC of 0.878 and Kaggle Test data AUC of 0.865. Even though the accuracy was not actually significant, I still decided to go for Hyperopt to get my hands on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tuning Hyper-Parameters\n",
    "**Hyper-paramters to optimize**\n",
    "* Max_depth: It sets the number of maximum tree depths. Increasing the depth makes the model complex and may lead to overfitting. Default value is 6. By going through few tutorials, I have kept the values from 4 to 8.\n",
    "* sample_rate: sample_rate tell XGBoost how much data sample should be collected to grow the tree. default is 1, which means 100% data is to be used. Higher values may increase the train accuracy, but for the accuracy on test data, sampling is suggested [Friedman, 1999](https://statweb.stanford.edu/~jhf/ftp/stobst.pdf). I have the values of 0.4, 0.6, 0.8 and 0.9\n",
    "* min_rows: Specify the minimum number of observations for a leaf. Default value is 1, but in our model, value 1 may make the algorithm time consuming and might not significantly improve the accuracy. Therefore, I have chosen value of 10,20,30 and 40\n",
    "* ntrees: It tell XGBoost the numbers of tree to build. I have tried 200 trees and observed that there is a need to build more trees to get it converged. Also, since we have taken small learn_rate values, we would require more tree. Therefore, I have set the values to 1000, 2000, 3000 and 4000.\n",
    "* learn_rate: As per my understanding, learn_rate here is similar to learning-rate in gradient boosting. I couldn't get much information from the H20 documentation. Therefore, I reviewed certain online blogs to see how others have comprehended and used this value. After researching for a while I selected 0.01, 0.005 and 0.001 because others have used these values in line to the number of trees we are using.\n",
    "\n",
    "**Fixed Hyper-parameters** have been discussed in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [4, 5, 6, 7, 8]\n",
    "sample_rate = [0.4, 0.6, 0.8, 0.9]\n",
    "min_rows = [10, 20, 30, 40] # \n",
    "ntrees = [1000, 2000, 3000, 4000]\n",
    "learn_rate = [0.01, 0.005, 0.001]\n",
    "\n",
    "search_crit = {'strategy': \"RandomDiscrete\",#  The default strategy, \"Cartesian\", covers the entire space of h-p \n",
    "               # combinations but takes too much time. Therefore we have used \"Random Discrete Strategy\"\n",
    "               \"max_runtime_secs\": 7200, #  maximum time allowed for he algorithm to run\n",
    "               \"max_models\": 10, # maximum models to return\n",
    "               \"seed\": 2020,  \n",
    "               \"stopping_rounds\" : 4, # Stops training when the option selected for stopping_metric doesn’t improve for\n",
    "               # the specified number of training rounds, based on a simple moving average. \n",
    "               \"stopping_metric\" : \"AUC\",# Since the kaggle score is based upon AUC, therefore I am using AUC as stopping metric\n",
    "               \"stopping_tolerance\" : 1e-3} # to stop training if the improvement is less than this value. 1e-3 is the default\n",
    "                # value\n",
    "\n",
    "hyper_params = {\n",
    "      \"ntrees\" : ntrees \n",
    "    , \"max_depth\" : max_depth \n",
    "    , \"learn_rate\" : learn_rate\n",
    "    , \"sample_rate\" : sample_rate\n",
    "    , \"min_rows\" : min_rows \n",
    "}\n",
    "XGB_grid = H2OGridSearch(H2OXGBoostEstimator(col_sample_rate_per_tree = .9, # Specify the column subsampling rate per tree. It\n",
    "                                             # is multiplicative with col_sample_rate, so setting both parameters to 0.8,\n",
    "                                             # for example, results in 64% of columns being considered at any given node to \n",
    "                                             # split.0.9 has been taken because it seemed the most common choice among the \n",
    "                                             # online blogs\n",
    "                                             score_tree_interval = 100, # Scoring the model after every so many trees\n",
    "                                             nfolds = 5 # nfolds ideally took more time but I believe it is the correct\n",
    "                                             # way of doing rather than taking validation set.\n",
    "                                            ),\n",
    "                         hyper_params=hyper_params,\n",
    "                         search_criteria=search_crit,\n",
    "                         grid_id='g2') # name of the grid\n",
    "\n",
    "XGB_grid.train(x=vars_to_use,\n",
    "               y='target',\n",
    "               training_frame=h2o_df_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    learn_rate max_depth min_rows ntrees sample_rate   model_ids  accuracy\n",
      "0        0.005         8     10.0   1360         0.8  g2_model_1  0.782824\n",
      "1        0.001         8     20.0     46         0.6  g2_model_2  0.773228\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploring the modesl \n",
    "XGB_grid.get_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator :  XGBoost\n",
      "Model Key:  g2_model_1\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.13601975447423742\n",
      "RMSE: 0.3688085607388167\n",
      "LogLoss: 0.4166825112634517\n",
      "Mean Per-Class Error: 0.2001375184104801\n",
      "AUC: 0.8892462043527933\n",
      "pr_auc: 0.8805401159906923\n",
      "Gini: 0.7784924087055867\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.41581707225976355: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>90664.0</td>\n",
       "<td>36505.0</td>\n",
       "<td>0.2871</td>\n",
       "<td> (36505.0/127169.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>15199.0</td>\n",
       "<td>107632.0</td>\n",
       "<td>0.1237</td>\n",
       "<td> (15199.0/122831.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>105863.0</td>\n",
       "<td>144137.0</td>\n",
       "<td>0.2068</td>\n",
       "<td> (51704.0/250000.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1       Error    Rate\n",
       "-----  ------  ------  -------  ------------------\n",
       "0      90664   36505   0.2871   (36505.0/127169.0)\n",
       "1      15199   107632  0.1237   (15199.0/122831.0)\n",
       "Total  105863  144137  0.2068   (51704.0/250000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4158171</td>\n",
       "<td>0.8063288</td>\n",
       "<td>232.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1889161</td>\n",
       "<td>0.8824624</td>\n",
       "<td>316.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6294731</td>\n",
       "<td>0.8092707</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5087246</td>\n",
       "<td>0.799644</td>\n",
       "<td>198.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9910524</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0077728</td>\n",
       "<td>1.0</td>\n",
       "<td>395.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9910524</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4889501</td>\n",
       "<td>0.5998570</td>\n",
       "<td>205.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5087246</td>\n",
       "<td>0.7994155</td>\n",
       "<td>198.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4889501</td>\n",
       "<td>0.7998625</td>\n",
       "<td>205.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.415817     0.806329  232\n",
       "max f2                       0.188916     0.882462  316\n",
       "max f0point5                 0.629473     0.809271  152\n",
       "max accuracy                 0.508725     0.799644  198\n",
       "max precision                0.991052     1         0\n",
       "max recall                   0.0077728    1         395\n",
       "max specificity              0.991052     1         0\n",
       "max absolute_mcc             0.48895      0.599857  205\n",
       "max min_per_class_accuracy   0.508725     0.799415  198\n",
       "max mean_per_class_accuracy  0.48895      0.799862  205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 49.13 %, avg score: 49.13 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.9805386</td>\n",
       "<td>2.0336886</td>\n",
       "<td>2.0336886</td>\n",
       "<td>0.9992</td>\n",
       "<td>0.9861304</td>\n",
       "<td>0.9992</td>\n",
       "<td>0.9861304</td>\n",
       "<td>0.0203369</td>\n",
       "<td>0.0203369</td>\n",
       "<td>103.3688564</td>\n",
       "<td>103.3688564</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.9694701</td>\n",
       "<td>2.0190343</td>\n",
       "<td>2.0263614</td>\n",
       "<td>0.992</td>\n",
       "<td>0.9748566</td>\n",
       "<td>0.9956</td>\n",
       "<td>0.9804935</td>\n",
       "<td>0.0201903</td>\n",
       "<td>0.0405272</td>\n",
       "<td>101.9034283</td>\n",
       "<td>102.6361423</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.9614959</td>\n",
       "<td>2.0198484</td>\n",
       "<td>2.0241904</td>\n",
       "<td>0.9924</td>\n",
       "<td>0.9652416</td>\n",
       "<td>0.9945333</td>\n",
       "<td>0.9754095</td>\n",
       "<td>0.0201985</td>\n",
       "<td>0.0607257</td>\n",
       "<td>101.9848410</td>\n",
       "<td>102.4190419</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.9552307</td>\n",
       "<td>2.0125213</td>\n",
       "<td>2.0212731</td>\n",
       "<td>0.9888</td>\n",
       "<td>0.9583069</td>\n",
       "<td>0.9931</td>\n",
       "<td>0.9711339</td>\n",
       "<td>0.0201252</td>\n",
       "<td>0.0808509</td>\n",
       "<td>101.2521269</td>\n",
       "<td>102.1273131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9494460</td>\n",
       "<td>1.9994952</td>\n",
       "<td>2.0169176</td>\n",
       "<td>0.9824</td>\n",
       "<td>0.9523305</td>\n",
       "<td>0.99096</td>\n",
       "<td>0.9673732</td>\n",
       "<td>0.0199950</td>\n",
       "<td>0.1008459</td>\n",
       "<td>99.9495241</td>\n",
       "<td>101.6917553</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9206736</td>\n",
       "<td>1.9682328</td>\n",
       "<td>1.9925752</td>\n",
       "<td>0.96704</td>\n",
       "<td>0.9352837</td>\n",
       "<td>0.979</td>\n",
       "<td>0.9513284</td>\n",
       "<td>0.0984116</td>\n",
       "<td>0.1992575</td>\n",
       "<td>96.8232775</td>\n",
       "<td>99.2575164</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.8828622</td>\n",
       "<td>1.8884484</td>\n",
       "<td>1.9578662</td>\n",
       "<td>0.92784</td>\n",
       "<td>0.9025077</td>\n",
       "<td>0.9619467</td>\n",
       "<td>0.9350548</td>\n",
       "<td>0.0944224</td>\n",
       "<td>0.2936799</td>\n",
       "<td>88.8448356</td>\n",
       "<td>95.7866228</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.8402481</td>\n",
       "<td>1.8085011</td>\n",
       "<td>1.9205249</td>\n",
       "<td>0.88856</td>\n",
       "<td>0.8617819</td>\n",
       "<td>0.9436</td>\n",
       "<td>0.9167366</td>\n",
       "<td>0.0904251</td>\n",
       "<td>0.3841050</td>\n",
       "<td>80.8501111</td>\n",
       "<td>92.0524949</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.7369484</td>\n",
       "<td>1.6486066</td>\n",
       "<td>1.8298855</td>\n",
       "<td>0.81</td>\n",
       "<td>0.7902756</td>\n",
       "<td>0.8990667</td>\n",
       "<td>0.8745829</td>\n",
       "<td>0.1648607</td>\n",
       "<td>0.5489657</td>\n",
       "<td>64.8606622</td>\n",
       "<td>82.9885507</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.6103108</td>\n",
       "<td>1.3960645</td>\n",
       "<td>1.7214303</td>\n",
       "<td>0.68592</td>\n",
       "<td>0.6739374</td>\n",
       "<td>0.84578</td>\n",
       "<td>0.8244216</td>\n",
       "<td>0.1396065</td>\n",
       "<td>0.6885721</td>\n",
       "<td>39.6064511</td>\n",
       "<td>72.1430258</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5019728</td>\n",
       "<td>1.1629800</td>\n",
       "<td>1.6097402</td>\n",
       "<td>0.5714</td>\n",
       "<td>0.5541872</td>\n",
       "<td>0.790904</td>\n",
       "<td>0.7703747</td>\n",
       "<td>0.1162980</td>\n",
       "<td>0.8048701</td>\n",
       "<td>16.2980029</td>\n",
       "<td>60.9740212</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.3878968</td>\n",
       "<td>0.8993658</td>\n",
       "<td>1.4913445</td>\n",
       "<td>0.44188</td>\n",
       "<td>0.4451642</td>\n",
       "<td>0.7327333</td>\n",
       "<td>0.7161729</td>\n",
       "<td>0.0899366</td>\n",
       "<td>0.8948067</td>\n",
       "<td>-10.0634205</td>\n",
       "<td>49.1344476</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.2626253</td>\n",
       "<td>0.6044077</td>\n",
       "<td>1.3646392</td>\n",
       "<td>0.29696</td>\n",
       "<td>0.3275653</td>\n",
       "<td>0.67048</td>\n",
       "<td>0.6606576</td>\n",
       "<td>0.0604408</td>\n",
       "<td>0.9552475</td>\n",
       "<td>-39.5592318</td>\n",
       "<td>36.4639220</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1350813</td>\n",
       "<td>0.3345247</td>\n",
       "<td>1.2358749</td>\n",
       "<td>0.16436</td>\n",
       "<td>0.1960728</td>\n",
       "<td>0.607215</td>\n",
       "<td>0.6025845</td>\n",
       "<td>0.0334525</td>\n",
       "<td>0.9886999</td>\n",
       "<td>-66.5475328</td>\n",
       "<td>23.5874901</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0309620</td>\n",
       "<td>0.1060807</td>\n",
       "<td>1.1103422</td>\n",
       "<td>0.05212</td>\n",
       "<td>0.0803580</td>\n",
       "<td>0.5455378</td>\n",
       "<td>0.5445593</td>\n",
       "<td>0.0106081</td>\n",
       "<td>0.9993080</td>\n",
       "<td>-89.3919287</td>\n",
       "<td>11.0342214</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0014679</td>\n",
       "<td>0.0069201</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0034</td>\n",
       "<td>0.0124197</td>\n",
       "<td>0.491324</td>\n",
       "<td>0.4913453</td>\n",
       "<td>0.0006920</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.3079923</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.980539           2.03369     2.03369            0.9992           0.98613    0.9992                      0.98613             0.0203369       0.0203369                  103.369   103.369\n",
       "    2        0.02                        0.96947            2.01903     2.02636            0.992            0.974857   0.9956                      0.980493            0.0201903       0.0405272                  101.903   102.636\n",
       "    3        0.03                        0.961496           2.01985     2.02419            0.9924           0.965242   0.994533                    0.97541             0.0201985       0.0607257                  101.985   102.419\n",
       "    4        0.04                        0.955231           2.01252     2.02127            0.9888           0.958307   0.9931                      0.971134            0.0201252       0.0808509                  101.252   102.127\n",
       "    5        0.05                        0.949446           1.9995      2.01692            0.9824           0.95233    0.99096                     0.967373            0.019995        0.100846                   99.9495   101.692\n",
       "    6        0.1                         0.920674           1.96823     1.99258            0.96704          0.935284   0.979                       0.951328            0.0984116       0.199258                   96.8233   99.2575\n",
       "    7        0.15                        0.882862           1.88845     1.95787            0.92784          0.902508   0.961947                    0.935055            0.0944224       0.29368                    88.8448   95.7866\n",
       "    8        0.2                         0.840248           1.8085      1.92052            0.88856          0.861782   0.9436                      0.916737            0.0904251       0.384105                   80.8501   92.0525\n",
       "    9        0.3                         0.736948           1.64861     1.82989            0.81             0.790276   0.899067                    0.874583            0.164861        0.548966                   64.8607   82.9886\n",
       "    10       0.4                         0.610311           1.39606     1.72143            0.68592          0.673937   0.84578                     0.824422            0.139606        0.688572                   39.6065   72.143\n",
       "    11       0.5                         0.501973           1.16298     1.60974            0.5714           0.554187   0.790904                    0.770375            0.116298        0.80487                    16.298    60.974\n",
       "    12       0.6                         0.387897           0.899366    1.49134            0.44188          0.445164   0.732733                    0.716173            0.0899366       0.894807                   -10.0634  49.1344\n",
       "    13       0.7                         0.262625           0.604408    1.36464            0.29696          0.327565   0.67048                     0.660658            0.0604408       0.955247                   -39.5592  36.4639\n",
       "    14       0.8                         0.135081           0.334525    1.23587            0.16436          0.196073   0.607215                    0.602584            0.0334525       0.9887                     -66.5475  23.5875\n",
       "    15       0.9                         0.030962           0.106081    1.11034            0.05212          0.080358   0.545538                    0.544559            0.0106081       0.999308                   -89.3919  11.0342\n",
       "    16       1                           0.00146787         0.00692008  1                  0.0034           0.0124197  0.491324                    0.491345            0.000692008     1                          -99.308   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.1419487460194194\n",
      "RMSE: 0.3767608605195335\n",
      "LogLoss: 0.433612396356896\n",
      "Mean Per-Class Error: 0.20900672194385894\n",
      "AUC: 0.8787883643498352\n",
      "pr_auc: 0.8688422794421169\n",
      "Gini: 0.7575767286996704\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4055378807417919: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>88100.0</td>\n",
       "<td>39069.0</td>\n",
       "<td>0.3072</td>\n",
       "<td> (39069.0/127169.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>15225.0</td>\n",
       "<td>107606.0</td>\n",
       "<td>0.124</td>\n",
       "<td> (15225.0/122831.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>103325.0</td>\n",
       "<td>146675.0</td>\n",
       "<td>0.2172</td>\n",
       "<td> (54294.0/250000.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1       Error    Rate\n",
       "-----  ------  ------  -------  ------------------\n",
       "0      88100   39069   0.3072   (39069.0/127169.0)\n",
       "1      15225   107606  0.124    (15225.0/122831.0)\n",
       "Total  103325  146675  0.2172   (54294.0/250000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4055379</td>\n",
       "<td>0.7985425</td>\n",
       "<td>240.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1918502</td>\n",
       "<td>0.8776325</td>\n",
       "<td>320.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6204113</td>\n",
       "<td>0.7986662</td>\n",
       "<td>156.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4913133</td>\n",
       "<td>0.79068</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9923445</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0035599</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9923445</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4826967</td>\n",
       "<td>0.5823093</td>\n",
       "<td>209.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5060866</td>\n",
       "<td>0.7896343</td>\n",
       "<td>200.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4826967</td>\n",
       "<td>0.7909933</td>\n",
       "<td>209.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.405538     0.798543  240\n",
       "max f2                       0.19185      0.877633  320\n",
       "max f0point5                 0.620411     0.798666  156\n",
       "max accuracy                 0.491313     0.79068   206\n",
       "max precision                0.992344     1         0\n",
       "max recall                   0.00355994   1         399\n",
       "max specificity              0.992344     1         0\n",
       "max absolute_mcc             0.482697     0.582309  209\n",
       "max min_per_class_accuracy   0.506087     0.789634  200\n",
       "max mean_per_class_accuracy  0.482697     0.790993  209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 49.13 %, avg score: 49.13 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.9796461</td>\n",
       "<td>2.0214767</td>\n",
       "<td>2.0214767</td>\n",
       "<td>0.9932</td>\n",
       "<td>0.9855846</td>\n",
       "<td>0.9932</td>\n",
       "<td>0.9855846</td>\n",
       "<td>0.0202148</td>\n",
       "<td>0.0202148</td>\n",
       "<td>102.1476663</td>\n",
       "<td>102.1476663</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.9688479</td>\n",
       "<td>2.0108930</td>\n",
       "<td>2.0161848</td>\n",
       "<td>0.988</td>\n",
       "<td>0.9741055</td>\n",
       "<td>0.9906</td>\n",
       "<td>0.9798450</td>\n",
       "<td>0.0201089</td>\n",
       "<td>0.0403237</td>\n",
       "<td>101.0893016</td>\n",
       "<td>101.6184839</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.9609281</td>\n",
       "<td>2.0027517</td>\n",
       "<td>2.0117071</td>\n",
       "<td>0.984</td>\n",
       "<td>0.9646940</td>\n",
       "<td>0.9884</td>\n",
       "<td>0.9747947</td>\n",
       "<td>0.0200275</td>\n",
       "<td>0.0603512</td>\n",
       "<td>100.2751748</td>\n",
       "<td>101.1707142</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.9544154</td>\n",
       "<td>1.9889116</td>\n",
       "<td>2.0060083</td>\n",
       "<td>0.9772</td>\n",
       "<td>0.9576528</td>\n",
       "<td>0.9856</td>\n",
       "<td>0.9705092</td>\n",
       "<td>0.0198891</td>\n",
       "<td>0.0802403</td>\n",
       "<td>98.8911594</td>\n",
       "<td>100.6008255</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9483850</td>\n",
       "<td>1.9872833</td>\n",
       "<td>2.0022633</td>\n",
       "<td>0.9764</td>\n",
       "<td>0.9514450</td>\n",
       "<td>0.98376</td>\n",
       "<td>0.9666964</td>\n",
       "<td>0.0198728</td>\n",
       "<td>0.1001132</td>\n",
       "<td>98.7283341</td>\n",
       "<td>100.2263272</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9190712</td>\n",
       "<td>1.9372960</td>\n",
       "<td>1.9697796</td>\n",
       "<td>0.95184</td>\n",
       "<td>0.9340544</td>\n",
       "<td>0.9678</td>\n",
       "<td>0.9503754</td>\n",
       "<td>0.0968648</td>\n",
       "<td>0.1969780</td>\n",
       "<td>93.7295959</td>\n",
       "<td>96.9779616</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.8815117</td>\n",
       "<td>1.8614193</td>\n",
       "<td>1.9336595</td>\n",
       "<td>0.91456</td>\n",
       "<td>0.9009667</td>\n",
       "<td>0.9500533</td>\n",
       "<td>0.9339058</td>\n",
       "<td>0.0930710</td>\n",
       "<td>0.2900489</td>\n",
       "<td>86.1419349</td>\n",
       "<td>93.3659527</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.8380019</td>\n",
       "<td>1.7754476</td>\n",
       "<td>1.8941065</td>\n",
       "<td>0.87232</td>\n",
       "<td>0.8601586</td>\n",
       "<td>0.93062</td>\n",
       "<td>0.9154690</td>\n",
       "<td>0.0887724</td>\n",
       "<td>0.3788213</td>\n",
       "<td>77.5447566</td>\n",
       "<td>89.4106537</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.7360088</td>\n",
       "<td>1.6274393</td>\n",
       "<td>1.8052175</td>\n",
       "<td>0.7996</td>\n",
       "<td>0.7885593</td>\n",
       "<td>0.8869467</td>\n",
       "<td>0.8731658</td>\n",
       "<td>0.1627439</td>\n",
       "<td>0.5415652</td>\n",
       "<td>62.7439327</td>\n",
       "<td>80.5217467</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.6087955</td>\n",
       "<td>1.3801890</td>\n",
       "<td>1.6989604</td>\n",
       "<td>0.67812</td>\n",
       "<td>0.6731243</td>\n",
       "<td>0.83474</td>\n",
       "<td>0.8231554</td>\n",
       "<td>0.1380189</td>\n",
       "<td>0.6795841</td>\n",
       "<td>38.0189040</td>\n",
       "<td>69.8960360</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5005043</td>\n",
       "<td>1.1608633</td>\n",
       "<td>1.5913409</td>\n",
       "<td>0.57036</td>\n",
       "<td>0.5529487</td>\n",
       "<td>0.781864</td>\n",
       "<td>0.7691141</td>\n",
       "<td>0.1160863</td>\n",
       "<td>0.7956705</td>\n",
       "<td>16.0863300</td>\n",
       "<td>59.1340948</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.3891465</td>\n",
       "<td>0.9063673</td>\n",
       "<td>1.4771787</td>\n",
       "<td>0.44532</td>\n",
       "<td>0.4452522</td>\n",
       "<td>0.7257733</td>\n",
       "<td>0.7151371</td>\n",
       "<td>0.0906367</td>\n",
       "<td>0.8863072</td>\n",
       "<td>-9.3632715</td>\n",
       "<td>47.7178671</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.2644243</td>\n",
       "<td>0.6254936</td>\n",
       "<td>1.3555094</td>\n",
       "<td>0.30732</td>\n",
       "<td>0.3293748</td>\n",
       "<td>0.6659943</td>\n",
       "<td>0.6600282</td>\n",
       "<td>0.0625494</td>\n",
       "<td>0.9488566</td>\n",
       "<td>-37.4506436</td>\n",
       "<td>35.5509370</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1368045</td>\n",
       "<td>0.3604953</td>\n",
       "<td>1.2311326</td>\n",
       "<td>0.17712</td>\n",
       "<td>0.1981031</td>\n",
       "<td>0.604885</td>\n",
       "<td>0.6022876</td>\n",
       "<td>0.0360495</td>\n",
       "<td>0.9849061</td>\n",
       "<td>-63.9504685</td>\n",
       "<td>23.1132613</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0323017</td>\n",
       "<td>0.1327841</td>\n",
       "<td>1.1090939</td>\n",
       "<td>0.06524</td>\n",
       "<td>0.0820556</td>\n",
       "<td>0.5449244</td>\n",
       "<td>0.5444840</td>\n",
       "<td>0.0132784</td>\n",
       "<td>0.9981845</td>\n",
       "<td>-86.7215931</td>\n",
       "<td>10.9093886</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0009345</td>\n",
       "<td>0.0181550</td>\n",
       "<td>1.0</td>\n",
       "<td>0.00892</td>\n",
       "<td>0.0129779</td>\n",
       "<td>0.491324</td>\n",
       "<td>0.4913334</td>\n",
       "<td>0.0018155</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.1844974</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.979646           2.02148   2.02148            0.9932           0.985585   0.9932                      0.985585            0.0202148       0.0202148                  102.148   102.148\n",
       "    2        0.02                        0.968848           2.01089   2.01618            0.988            0.974105   0.9906                      0.979845            0.0201089       0.0403237                  101.089   101.618\n",
       "    3        0.03                        0.960928           2.00275   2.01171            0.984            0.964694   0.9884                      0.974795            0.0200275       0.0603512                  100.275   101.171\n",
       "    4        0.04                        0.954415           1.98891   2.00601            0.9772           0.957653   0.9856                      0.970509            0.0198891       0.0802403                  98.8912   100.601\n",
       "    5        0.05                        0.948385           1.98728   2.00226            0.9764           0.951445   0.98376                     0.966696            0.0198728       0.100113                   98.7283   100.226\n",
       "    6        0.1                         0.919071           1.9373    1.96978            0.95184          0.934054   0.9678                      0.950375            0.0968648       0.196978                   93.7296   96.978\n",
       "    7        0.15                        0.881512           1.86142   1.93366            0.91456          0.900967   0.950053                    0.933906            0.093071        0.290049                   86.1419   93.366\n",
       "    8        0.2                         0.838002           1.77545   1.89411            0.87232          0.860159   0.93062                     0.915469            0.0887724       0.378821                   77.5448   89.4107\n",
       "    9        0.3                         0.736009           1.62744   1.80522            0.7996           0.788559   0.886947                    0.873166            0.162744        0.541565                   62.7439   80.5217\n",
       "    10       0.4                         0.608795           1.38019   1.69896            0.67812          0.673124   0.83474                     0.823155            0.138019        0.679584                   38.0189   69.896\n",
       "    11       0.5                         0.500504           1.16086   1.59134            0.57036          0.552949   0.781864                    0.769114            0.116086        0.79567                    16.0863   59.1341\n",
       "    12       0.6                         0.389146           0.906367  1.47718            0.44532          0.445252   0.725773                    0.715137            0.0906367       0.886307                   -9.36327  47.7179\n",
       "    13       0.7                         0.264424           0.625494  1.35551            0.30732          0.329375   0.665994                    0.660028            0.0625494       0.948857                   -37.4506  35.5509\n",
       "    14       0.8                         0.136805           0.360495  1.23113            0.17712          0.198103   0.604885                    0.602288            0.0360495       0.984906                   -63.9505  23.1133\n",
       "    15       0.9                         0.0323017          0.132784  1.10909            0.06524          0.0820556  0.544924                    0.544484            0.0132784       0.998184                   -86.7216  10.9094\n",
       "    16       1                           0.000934468        0.018155  1                  0.00892          0.0129779  0.491324                    0.491333            0.0018155       1                          -98.1845  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.7834026</td>\n",
       "<td>0.0027226</td>\n",
       "<td>0.7775557</td>\n",
       "<td>0.7822458</td>\n",
       "<td>0.7848795</td>\n",
       "<td>0.7829144</td>\n",
       "<td>0.7894177</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8788035</td>\n",
       "<td>0.0016760</td>\n",
       "<td>0.8773696</td>\n",
       "<td>0.8765165</td>\n",
       "<td>0.8774911</td>\n",
       "<td>0.8795294</td>\n",
       "<td>0.8831111</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2165974</td>\n",
       "<td>0.0027226</td>\n",
       "<td>0.2224443</td>\n",
       "<td>0.2177542</td>\n",
       "<td>0.2151206</td>\n",
       "<td>0.2170856</td>\n",
       "<td>0.2105823</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>10830.0</td>\n",
       "<td>142.37346</td>\n",
       "<td>11130.0</td>\n",
       "<td>10879.0</td>\n",
       "<td>10804.0</td>\n",
       "<td>10838.0</td>\n",
       "<td>10499.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.7590598</td>\n",
       "<td>0.0038358</td>\n",
       "<td>0.7505828</td>\n",
       "<td>0.7582756</td>\n",
       "<td>0.7635419</td>\n",
       "<td>0.7568046</td>\n",
       "<td>0.7660941</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7989224</td>\n",
       "<td>0.0015456</td>\n",
       "<td>0.7982818</td>\n",
       "<td>0.7951263</td>\n",
       "<td>0.7993165</td>\n",
       "<td>0.8015527</td>\n",
       "<td>0.8003347</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.8433018</td>\n",
       "<td>0.0051752</td>\n",
       "<td>0.8524548</td>\n",
       "<td>0.8357416</td>\n",
       "<td>0.8386081</td>\n",
       "<td>0.8519251</td>\n",
       "<td>0.8377793</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.0216014</td>\n",
       "<td>0.0111948</td>\n",
       "<td>2.0042074</td>\n",
       "<td>2.0352557</td>\n",
       "<td>2.0077214</td>\n",
       "<td>2.0159836</td>\n",
       "<td>2.0448399</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.4336052</td>\n",
       "<td>0.0029183</td>\n",
       "<td>0.4356759</td>\n",
       "<td>0.4371350</td>\n",
       "<td>0.4367163</td>\n",
       "<td>0.4324740</td>\n",
       "<td>0.4260249</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3059365</td>\n",
       "<td>0.0133243</td>\n",
       "<td>0.3345422</td>\n",
       "<td>0.2969483</td>\n",
       "<td>0.2953517</td>\n",
       "<td>0.3204394</td>\n",
       "<td>0.2824009</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5786898</td>\n",
       "<td>0.0037334</td>\n",
       "<td>0.572212</td>\n",
       "<td>0.574513</td>\n",
       "<td>0.5786825</td>\n",
       "<td>0.5806196</td>\n",
       "<td>0.5874222</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7849321</td>\n",
       "<td>0.0027231</td>\n",
       "<td>0.7791532</td>\n",
       "<td>0.7841283</td>\n",
       "<td>0.7858348</td>\n",
       "<td>0.7843692</td>\n",
       "<td>0.7911754</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2150679</td>\n",
       "<td>0.0027231</td>\n",
       "<td>0.2208469</td>\n",
       "<td>0.2158717</td>\n",
       "<td>0.2141652</td>\n",
       "<td>0.2156308</td>\n",
       "<td>0.2088247</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1419465</td>\n",
       "<td>0.0010183</td>\n",
       "<td>0.1427162</td>\n",
       "<td>0.1433694</td>\n",
       "<td>0.1427589</td>\n",
       "<td>0.1415793</td>\n",
       "<td>0.1393088</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.7346592</td>\n",
       "<td>0.0058315</td>\n",
       "<td>0.7218289</td>\n",
       "<td>0.7355493</td>\n",
       "<td>0.7414197</td>\n",
       "<td>0.7296487</td>\n",
       "<td>0.7448496</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.4320282</td>\n",
       "<td>0.0040455</td>\n",
       "<td>0.4290223</td>\n",
       "<td>0.4262131</td>\n",
       "<td>0.4288852</td>\n",
       "<td>0.4335738</td>\n",
       "<td>0.4424467</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8758008</td>\n",
       "<td>0.0088374</td>\n",
       "<td>0.8928484</td>\n",
       "<td>0.8652049</td>\n",
       "<td>0.8670213</td>\n",
       "<td>0.8891778</td>\n",
       "<td>0.8647516</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3767530</td>\n",
       "<td>0.0013548</td>\n",
       "<td>0.3777780</td>\n",
       "<td>0.3786415</td>\n",
       "<td>0.3778345</td>\n",
       "<td>0.3762702</td>\n",
       "<td>0.3732409</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6940635</td>\n",
       "<td>0.0133243</td>\n",
       "<td>0.6654578</td>\n",
       "<td>0.7030516</td>\n",
       "<td>0.7046483</td>\n",
       "<td>0.6795606</td>\n",
       "<td>0.7175991</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.783403  0.0027226   0.777556      0.782246      0.784879      0.782914      0.789418\n",
       "auc                      0.878804  0.00167602  0.87737       0.876517      0.877491      0.879529      0.883111\n",
       "err                      0.216597  0.0027226   0.222444      0.217754      0.215121      0.217086      0.210582\n",
       "err_count                10830     142.373     11130         10879         10804         10838         10499\n",
       "f0point5                 0.75906   0.00383577  0.750583      0.758276      0.763542      0.756805      0.766094\n",
       "f1                       0.798922  0.00154562  0.798282      0.795126      0.799316      0.801553      0.800335\n",
       "f2                       0.843302  0.00517518  0.852455      0.835742      0.838608      0.851925      0.837779\n",
       "lift_top_group           2.0216    0.0111948   2.00421       2.03526       2.00772       2.01598       2.04484\n",
       "logloss                  0.433605  0.00291833  0.435676      0.437135      0.436716      0.432474      0.426025\n",
       "max_per_class_error      0.305937  0.0133243   0.334542      0.296948      0.295352      0.320439      0.282401\n",
       "mcc                      0.57869   0.00373345  0.572212      0.574513      0.578682      0.58062       0.587422\n",
       "mean_per_class_accuracy  0.784932  0.00272309  0.779153      0.784128      0.785835      0.784369      0.791175\n",
       "mean_per_class_error     0.215068  0.00272309  0.220847      0.215872      0.214165      0.215631      0.208825\n",
       "mse                      0.141947  0.00101831  0.142716      0.143369      0.142759      0.141579      0.139309\n",
       "precision                0.734659  0.00583148  0.721829      0.735549      0.74142       0.729649      0.74485\n",
       "r2                       0.432028  0.00404552  0.429022      0.426213      0.428885      0.433574      0.442447\n",
       "recall                   0.875801  0.00883744  0.892848      0.865205      0.867021      0.889178      0.864752\n",
       "rmse                     0.376753  0.00135479  0.377778      0.378642      0.377835      0.37627       0.373241\n",
       "specificity              0.694064  0.0133243   0.665458      0.703052      0.704648      0.679561      0.717599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:16:51</td>\n",
       "<td> 1:38:02.233</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.508676</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:18:05</td>\n",
       "<td> 1:39:15.936</td>\n",
       "<td>100.0</td>\n",
       "<td>0.4349465</td>\n",
       "<td>0.5680203</td>\n",
       "<td>0.8718468</td>\n",
       "<td>0.8619663</td>\n",
       "<td>2.0117071</td>\n",
       "<td>0.225152</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:19:15</td>\n",
       "<td> 1:40:26.730</td>\n",
       "<td>200.0</td>\n",
       "<td>0.4040003</td>\n",
       "<td>0.5063546</td>\n",
       "<td>0.8743722</td>\n",
       "<td>0.8654553</td>\n",
       "<td>2.0198484</td>\n",
       "<td>0.2203</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:20:28</td>\n",
       "<td> 1:41:39.228</td>\n",
       "<td>300.0</td>\n",
       "<td>0.3896965</td>\n",
       "<td>0.4736329</td>\n",
       "<td>0.8763788</td>\n",
       "<td>0.8677672</td>\n",
       "<td>2.0214767</td>\n",
       "<td>0.21852</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:21:42</td>\n",
       "<td> 1:42:53.173</td>\n",
       "<td>400.0</td>\n",
       "<td>0.3829362</td>\n",
       "<td>0.4555570</td>\n",
       "<td>0.8780196</td>\n",
       "<td>0.8699982</td>\n",
       "<td>2.0247332</td>\n",
       "<td>0.218492</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:22:57</td>\n",
       "<td> 1:44:08.310</td>\n",
       "<td>500.0</td>\n",
       "<td>0.3794422</td>\n",
       "<td>0.4448940</td>\n",
       "<td>0.8792473</td>\n",
       "<td>0.8705343</td>\n",
       "<td>2.0271756</td>\n",
       "<td>0.214904</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:24:14</td>\n",
       "<td> 1:45:25.659</td>\n",
       "<td>600.0</td>\n",
       "<td>0.3774516</td>\n",
       "<td>0.4383575</td>\n",
       "<td>0.8802815</td>\n",
       "<td>0.8716622</td>\n",
       "<td>2.0296179</td>\n",
       "<td>0.214676</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:25:32</td>\n",
       "<td> 1:46:43.684</td>\n",
       "<td>700.0</td>\n",
       "<td>0.3760536</td>\n",
       "<td>0.4338692</td>\n",
       "<td>0.8813051</td>\n",
       "<td>0.8713452</td>\n",
       "<td>2.0312462</td>\n",
       "<td>0.214808</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:26:52</td>\n",
       "<td> 1:48:02.985</td>\n",
       "<td>800.0</td>\n",
       "<td>0.3748880</td>\n",
       "<td>0.4304762</td>\n",
       "<td>0.8823938</td>\n",
       "<td>0.8727218</td>\n",
       "<td>2.0328744</td>\n",
       "<td>0.21252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:28:14</td>\n",
       "<td> 1:49:24.995</td>\n",
       "<td>900.0</td>\n",
       "<td>0.3738237</td>\n",
       "<td>0.4276517</td>\n",
       "<td>0.8834868</td>\n",
       "<td>0.8741974</td>\n",
       "<td>2.0336886</td>\n",
       "<td>0.21114</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:29:37</td>\n",
       "<td> 1:50:47.865</td>\n",
       "<td>1000.0</td>\n",
       "<td>0.3727844</td>\n",
       "<td>0.4251396</td>\n",
       "<td>0.8846409</td>\n",
       "<td>0.8758156</td>\n",
       "<td>2.0336886</td>\n",
       "<td>0.211004</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:31:01</td>\n",
       "<td> 1:52:11.881</td>\n",
       "<td>1100.0</td>\n",
       "<td>0.3716488</td>\n",
       "<td>0.4226279</td>\n",
       "<td>0.8859543</td>\n",
       "<td>0.8771471</td>\n",
       "<td>2.0336886</td>\n",
       "<td>0.211176</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:32:26</td>\n",
       "<td> 1:53:37.643</td>\n",
       "<td>1200.0</td>\n",
       "<td>0.3704983</td>\n",
       "<td>0.4201699</td>\n",
       "<td>0.8872817</td>\n",
       "<td>0.8777343</td>\n",
       "<td>2.0345027</td>\n",
       "<td>0.209192</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:33:56</td>\n",
       "<td> 1:55:07.299</td>\n",
       "<td>1300.0</td>\n",
       "<td>0.3694289</td>\n",
       "<td>0.4179455</td>\n",
       "<td>0.8885242</td>\n",
       "<td>0.8796694</td>\n",
       "<td>2.0345027</td>\n",
       "<td>0.207552</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-11 20:35:00</td>\n",
       "<td> 1:56:11.105</td>\n",
       "<td>1360.0</td>\n",
       "<td>0.3688086</td>\n",
       "<td>0.4166825</td>\n",
       "<td>0.8892462</td>\n",
       "<td>0.8805401</td>\n",
       "<td>2.0336886</td>\n",
       "<td>0.206816</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration     number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  -----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2020-07-11 20:16:51  1:38:02.233  0                  0.5              0.693147            0.5             0                  1                0.508676\n",
       "    2020-07-11 20:18:05  1:39:15.936  100                0.434947         0.56802             0.871847        0.861966           2.01171          0.225152\n",
       "    2020-07-11 20:19:15  1:40:26.730  200                0.404            0.506355            0.874372        0.865455           2.01985          0.2203\n",
       "    2020-07-11 20:20:28  1:41:39.228  300                0.389696         0.473633            0.876379        0.867767           2.02148          0.21852\n",
       "    2020-07-11 20:21:42  1:42:53.173  400                0.382936         0.455557            0.87802         0.869998           2.02473          0.218492\n",
       "    2020-07-11 20:22:57  1:44:08.310  500                0.379442         0.444894            0.879247        0.870534           2.02718          0.214904\n",
       "    2020-07-11 20:24:14  1:45:25.659  600                0.377452         0.438357            0.880281        0.871662           2.02962          0.214676\n",
       "    2020-07-11 20:25:32  1:46:43.684  700                0.376054         0.433869            0.881305        0.871345           2.03125          0.214808\n",
       "    2020-07-11 20:26:52  1:48:02.985  800                0.374888         0.430476            0.882394        0.872722           2.03287          0.21252\n",
       "    2020-07-11 20:28:14  1:49:24.995  900                0.373824         0.427652            0.883487        0.874197           2.03369          0.21114\n",
       "    2020-07-11 20:29:37  1:50:47.865  1000               0.372784         0.42514             0.884641        0.875816           2.03369          0.211004\n",
       "    2020-07-11 20:31:01  1:52:11.881  1100               0.371649         0.422628            0.885954        0.877147           2.03369          0.211176\n",
       "    2020-07-11 20:32:26  1:53:37.643  1200               0.370498         0.42017             0.887282        0.877734           2.0345           0.209192\n",
       "    2020-07-11 20:33:56  1:55:07.299  1300               0.369429         0.417946            0.888524        0.879669           2.0345           0.207552\n",
       "    2020-07-11 20:35:00  1:56:11.105  1360               0.368809         0.416683            0.889246        0.88054            2.03369          0.206816"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>f10</td>\n",
       "<td>7722454.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6846953</td></tr>\n",
       "<tr><td>e19</td>\n",
       "<td>871827.1875000</td>\n",
       "<td>0.1128951</td>\n",
       "<td>0.0772987</td></tr>\n",
       "<tr><td>e18</td>\n",
       "<td>240750.7656250</td>\n",
       "<td>0.0311754</td>\n",
       "<td>0.0213457</td></tr>\n",
       "<tr><td>f02</td>\n",
       "<td>227124.7812500</td>\n",
       "<td>0.0294110</td>\n",
       "<td>0.0201375</td></tr>\n",
       "<tr><td>f27.F</td>\n",
       "<td>186000.6406250</td>\n",
       "<td>0.0240857</td>\n",
       "<td>0.0164914</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>f09.K</td>\n",
       "<td>8.9732685</td>\n",
       "<td>0.0000012</td>\n",
       "<td>0.0000008</td></tr>\n",
       "<tr><td>c05.C</td>\n",
       "<td>7.6248779</td>\n",
       "<td>0.0000010</td>\n",
       "<td>0.0000007</td></tr>\n",
       "<tr><td>b03.N</td>\n",
       "<td>6.3360138</td>\n",
       "<td>0.0000008</td>\n",
       "<td>0.0000006</td></tr>\n",
       "<tr><td>b02.N</td>\n",
       "<td>3.8477745</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.0000003</td></tr>\n",
       "<tr><td>a12.E</td>\n",
       "<td>2.4519043</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0000002</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance      percentage\n",
       "----------  ---------------------  ---------------------  ----------------------\n",
       "f10         7722454.0              1.0                    0.6846953073660439\n",
       "e19         871827.1875            0.1128950962349533     0.07729874261671045\n",
       "e18         240750.765625          0.03117542242724916    0.021345665441091625\n",
       "f02         227124.78125           0.02941095942429699    0.020137545902949274\n",
       "f27.F       186000.640625          0.02408569097659889    0.016491359586345927\n",
       "---         ---                    ---                    ---\n",
       "f09.K       8.973268508911133      1.161971118107163e-06  7.955961718628496e-07\n",
       "c05.C       7.6248779296875        9.8736462913052e-07    6.760439282248813e-07\n",
       "b03.N       6.3360137939453125     8.204663691030484e-07  5.617694727765137e-07\n",
       "b02.N       3.8477745056152344     4.982580026524255e-07  3.4115491627369366e-07\n",
       "a12.E       2.451904296875         3.175032569795819e-07  2.1739299012735485e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model\n",
    "best_XG_Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e20' has levels not trained on: [30146, BE271, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e13' has levels not trained on: [Q, S]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e24' has levels not trained on: [J, M, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e03' has levels not trained on: [J, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'c09' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'a18' has levels not trained on: [D]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "# Implementin the model to test data\n",
    "grid_XGBoost = XGB_grid.get_grid(sort_by='accuracy', decreasing=True)\n",
    "best_XG_Grid = grid_XGBoost.models[0]\n",
    "\n",
    "\n",
    "preds = best_XG_Grid.predict(h2o_df_test)\n",
    "df_test['Predicted'] = np.round(preds[2].as_data_frame(), 5)\n",
    "df_preds_dt = df_test[['unique_id', 'Predicted']].copy()\n",
    "df_test[['unique_id', 'Predicted']].to_csv(dirPOutput + '250k_XGBoost_Grid.csv', index=False)\n",
    "\n",
    "# Kaggle Accuracy\n",
    "# Accuracy = 0.86532\n",
    "# From 0.8381"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train data into valid data rather than n-folds because of speed efficiency. Even though I would prefer n-folds, I\n",
    "# wanted to make this experiements since majority of people have used it in this way\n",
    "train, valid = h2o_df_train.split_frame(ratios=[.7], seed = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H20 Documentation says that the dependent variable has to be in factors\n",
    "train[var_dep] = train[var_dep].asfactor()\n",
    "valid[var_dep]   = valid[var_dep].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective\n",
    "def hyperopt_objective(params):\n",
    "    XGB_hpropt = H2OXGBoostEstimator(col_sample_rate_per_tree = .9, # Specify the column subsampling rate per tree. It\n",
    "                                    # is multiplicative with col_sample_rate, so setting both parameters to 0.8, for example,\n",
    "                                    # results in 64% of columns being considered at any given node to split.\n",
    "                                    # 0.9 has been taken because it seemed the most common choice among the online blogs\n",
    "                                   score_tree_interval = 100, # Scoring the model after every so many trees\n",
    "                                   seed = 2020, max_runtime_secs= 1800, # Each XGBoost will run for maximum 30 minutes\n",
    "                                   stopping_rounds = 4,  # Stops training when the option selected for stopping_metric doesn’t\n",
    "                                    # improve for the specified number of  training rounds, based on a simple moving average. \n",
    "                                   stopping_metric = \"AUC\", # Since the kaggle score is based upon AUC, therefore I am using AUC as metrc\n",
    "                                   stopping_tolerance = 1e-3, # to stop training if the improvement is less than this value. 1e-3 is the\n",
    "                                     # default value\n",
    "                                   ntrees = int(params['ntrees']), # Discussed under \"Hyper-parameters to optimise\"\n",
    "                                   max_depth = int(params['max_depth']), # Discussed under \"Hyper-parameters to optimise\"\n",
    "                                   learn_rate = params['learn_rate'], # Discussed under \"Hyper-parameters to optimise\"\n",
    "                                   sample_rate = params['sample_rate'], # Discussed under \"Hyper-parameters to optimise\"\n",
    "                                   min_rows = params['min_rows'] # Discussed under \"Hyper-parameters to optimise\"\n",
    "                                   # ,max_runtime_secs = 18000, \n",
    "                                  )\n",
    "    \n",
    "    \n",
    "    # training the model\n",
    "    XGB_hpropt.train(x=vars_to_use,\n",
    "               y='target',\n",
    "               training_frame=train)\n",
    "    \n",
    "\n",
    "    # validating the model on validation frame\n",
    "    preds = XGB_hpropt.predict(valid)\n",
    "    preds = preds[2].as_data_frame()['p1'].values\n",
    "    score = roc_auc_score(valid[var_dep].as_data_frame().as_matrix(), preds)\n",
    "    \n",
    "    return -score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Space\n",
    "search_space = {\n",
    "    'ntrees': hyperopt.hp.quniform('ntrees', 1200, 4000, 1)\n",
    "    , 'max_depth': hyperopt.hp.quniform('max_depth', 4,8, 1)\n",
    "    , 'learn_rate': hyperopt.hp.uniform('learn_rate', 0.001, 0.01)\n",
    "    , 'sample_rate': hyperopt.hp.uniform('sample_rate', 0.4, 0.9)\n",
    "    , 'min_rows': hyperopt.hp.quniform('min_rows', 10 , 40, 1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [30:57<4:38:35, 1857.28s/it, best loss: -0.8810321924378307]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [58:04<3:58:25, 1788.15s/it, best loss: -0.8811926515395831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [1:04:12<2:38:54, 1362.09s/it, best loss: -0.8811926515395831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [1:33:56<2:28:53, 1488.83s/it, best loss: -0.8820504208614022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [2:00:04<2:06:02, 1512.51s/it, best loss: -0.8820504208614022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [2:31:02<1:47:45, 1616.27s/it, best loss: -0.8820643226233149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [2:45:01<1:09:09, 1383.06s/it, best loss: -0.8820643226233149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [2:55:17<38:25, 1152.86s/it, best loss: -0.8820643226233149]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [3:26:04<22:41, 1361.22s/it, best loss: -0.8820643226233149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [3:40:01<00:00, 1203.76s/it, best loss: -0.8820643226233149]\n",
      "{'learn_rate': 0.00632500998161564, 'max_depth': 8.0, 'min_rows': 37.0, 'ntrees': 3785.0, 'sample_rate': 0.7140605409926624}\n"
     ]
    }
   ],
   "source": [
    "# Optimisation\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "h2o.no_progress()\n",
    "best = hyperopt.fmin(hyperopt_objective,\n",
    "                     space=search_space,\n",
    "                     algo=hyperopt.tpe.suggest,\n",
    "                     max_evals=10, # Each model will take 30 minutes and there will be 10 models like this, thus 5 hours\n",
    "                     trials=trials,\n",
    "                     rstate=RandomState(2020)\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-377027ff61a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "# The best model returned the value of \n",
    "#     {'learn_rate': 0.00632500998161564,\n",
    "#      'max_depth': 8.0,\n",
    "#      'min_rows': 37.0,\n",
    "#      'ntrees': 3785.0,\n",
    "#      'sample_rate': 0.7140605409926624}\n",
    "\n",
    "# I actually did not run the model next time but by mistake run this cell, therefore got this error\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost Model Build progress: |███████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Implementing the best model returned by Hyperopt\n",
    "XGB_hpropt_bst = H2OXGBoostEstimator(col_sample_rate_per_tree = .9,\n",
    "                               score_tree_interval = 100,\n",
    "                               seed = 2020, max_runtime_secs= 3600,\n",
    "                               stopping_rounds = 4, \n",
    "                               stopping_metric = \"AUC\", \n",
    "                               stopping_tolerance = 1e-3,\n",
    "                               ntrees = 3785,\n",
    "                               max_depth = 8,\n",
    "                               learn_rate = 0.00632500998161564,\n",
    "                               sample_rate = 0.7140605409926624,\n",
    "                               min_rows = 37, nfolds = 5\n",
    "                               # ,max_runtime_secs = 18000, \n",
    "                              )\n",
    "\n",
    "\n",
    "XGB_hpropt_bst.train(x=vars_to_use,\n",
    "           y='target',\n",
    "           training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e20' has levels not trained on: [30146, BE271, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e13' has levels not trained on: [Q, S]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e24' has levels not trained on: [J, M, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e03' has levels not trained on: [J, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'f03_e11' has levels not trained on: [C_G]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'c09' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'a18' has levels not trained on: [D]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "preds = XGB_hpropt_bst.predict(h2o_df_test)\n",
    "df_test['Predicted'] = np.round(preds[2].as_data_frame(), 5)\n",
    "df_preds_dt = df_test[['unique_id', 'Predicted']].copy()\n",
    "df_test[['unique_id', 'Predicted']].to_csv(dirPOutput + '250k_XGBoost_hyperoptt_test_2ndver.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator :  XGBoost\n",
      "Model Key:  XGBoost_model_python_1594806448431_1\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.13771069972813313\n",
      "RMSE: 0.37109392305470745\n",
      "LogLoss: 0.42207939087711466\n",
      "Mean Per-Class Error: 0.20218874513834284\n",
      "AUC: 0.8863087173166594\n",
      "pr_auc: 0.8771276603825596\n",
      "Gini: 0.7726174346333188\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4171403104482695: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>63288.0</td>\n",
       "<td>25722.0</td>\n",
       "<td>0.289</td>\n",
       "<td> (25722.0/89010.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>10819.0</td>\n",
       "<td>75329.0</td>\n",
       "<td>0.1256</td>\n",
       "<td> (10819.0/86148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>74107.0</td>\n",
       "<td>101051.0</td>\n",
       "<td>0.2086</td>\n",
       "<td> (36541.0/175158.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1       Error    Rate\n",
       "-----  -----  ------  -------  ------------------\n",
       "0      63288  25722   0.289    (25722.0/89010.0)\n",
       "1      10819  75329   0.1256   (10819.0/86148.0)\n",
       "Total  74107  101051  0.2086   (36541.0/175158.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4171403</td>\n",
       "<td>0.8048013</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1880436</td>\n",
       "<td>0.8816929</td>\n",
       "<td>318.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6272633</td>\n",
       "<td>0.8067679</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4848333</td>\n",
       "<td>0.7974457</td>\n",
       "<td>204.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9876546</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0062810</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9876546</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4830881</td>\n",
       "<td>0.5959146</td>\n",
       "<td>205.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5073536</td>\n",
       "<td>0.7962813</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4848333</td>\n",
       "<td>0.7978113</td>\n",
       "<td>204.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.41714      0.804801  231\n",
       "max f2                       0.188044     0.881693  318\n",
       "max f0point5                 0.627263     0.806768  150\n",
       "max accuracy                 0.484833     0.797446  204\n",
       "max precision                0.987655     1         0\n",
       "max recall                   0.00628103   1         398\n",
       "max specificity              0.987655     1         0\n",
       "max absolute_mcc             0.483088     0.595915  205\n",
       "max min_per_class_accuracy   0.507354     0.796281  195\n",
       "max mean_per_class_accuracy  0.484833     0.797811  204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 49.18 %, avg score: 49.19 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100024</td>\n",
       "<td>0.9777053</td>\n",
       "<td>2.0216167</td>\n",
       "<td>2.0216167</td>\n",
       "<td>0.9942922</td>\n",
       "<td>0.9827959</td>\n",
       "<td>0.9942922</td>\n",
       "<td>0.9827959</td>\n",
       "<td>0.0202210</td>\n",
       "<td>0.0202210</td>\n",
       "<td>102.1616749</td>\n",
       "<td>102.1616749</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200048</td>\n",
       "<td>0.9677721</td>\n",
       "<td>2.0158142</td>\n",
       "<td>2.0187155</td>\n",
       "<td>0.9914384</td>\n",
       "<td>0.9724900</td>\n",
       "<td>0.9928653</td>\n",
       "<td>0.9776429</td>\n",
       "<td>0.0201630</td>\n",
       "<td>0.0403840</td>\n",
       "<td>101.5814175</td>\n",
       "<td>101.8715462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300015</td>\n",
       "<td>0.9601332</td>\n",
       "<td>2.0134819</td>\n",
       "<td>2.0169716</td>\n",
       "<td>0.9902913</td>\n",
       "<td>0.9638160</td>\n",
       "<td>0.9920076</td>\n",
       "<td>0.9730357</td>\n",
       "<td>0.0201282</td>\n",
       "<td>0.0605121</td>\n",
       "<td>101.3481879</td>\n",
       "<td>101.6971598</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400039</td>\n",
       "<td>0.9536010</td>\n",
       "<td>2.0111721</td>\n",
       "<td>2.0155215</td>\n",
       "<td>0.9891553</td>\n",
       "<td>0.9568361</td>\n",
       "<td>0.9912944</td>\n",
       "<td>0.9689852</td>\n",
       "<td>0.0201165</td>\n",
       "<td>0.0806287</td>\n",
       "<td>101.1172116</td>\n",
       "<td>101.5521521</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500006</td>\n",
       "<td>0.9473292</td>\n",
       "<td>1.9972254</td>\n",
       "<td>2.0118635</td>\n",
       "<td>0.9822958</td>\n",
       "<td>0.9504915</td>\n",
       "<td>0.9894953</td>\n",
       "<td>0.9652877</td>\n",
       "<td>0.0199656</td>\n",
       "<td>0.1005943</td>\n",
       "<td>99.7225393</td>\n",
       "<td>101.1863549</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000011</td>\n",
       "<td>0.9174969</td>\n",
       "<td>1.9535924</td>\n",
       "<td>1.9827280</td>\n",
       "<td>0.9608358</td>\n",
       "<td>0.9327099</td>\n",
       "<td>0.9751656</td>\n",
       "<td>0.9489988</td>\n",
       "<td>0.0976807</td>\n",
       "<td>0.1982751</td>\n",
       "<td>95.3592403</td>\n",
       "<td>98.2727976</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500017</td>\n",
       "<td>0.8797814</td>\n",
       "<td>1.8795347</td>\n",
       "<td>1.9483302</td>\n",
       "<td>0.9244120</td>\n",
       "<td>0.8996772</td>\n",
       "<td>0.9582477</td>\n",
       "<td>0.9325583</td>\n",
       "<td>0.0939778</td>\n",
       "<td>0.2922529</td>\n",
       "<td>87.9534652</td>\n",
       "<td>94.8330201</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000023</td>\n",
       "<td>0.8372408</td>\n",
       "<td>1.7892260</td>\n",
       "<td>1.9085541</td>\n",
       "<td>0.8799954</td>\n",
       "<td>0.8589350</td>\n",
       "<td>0.9386846</td>\n",
       "<td>0.9141524</td>\n",
       "<td>0.0894623</td>\n",
       "<td>0.3817152</td>\n",
       "<td>78.9225983</td>\n",
       "<td>90.8554147</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000034</td>\n",
       "<td>0.7372544</td>\n",
       "<td>1.6485395</td>\n",
       "<td>1.8218826</td>\n",
       "<td>0.8108016</td>\n",
       "<td>0.7884930</td>\n",
       "<td>0.8960569</td>\n",
       "<td>0.8722660</td>\n",
       "<td>0.1648558</td>\n",
       "<td>0.5465710</td>\n",
       "<td>64.8539472</td>\n",
       "<td>82.1882588</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3999989</td>\n",
       "<td>0.6122937</td>\n",
       "<td>1.3906936</td>\n",
       "<td>1.7140900</td>\n",
       "<td>0.6839852</td>\n",
       "<td>0.6760560</td>\n",
       "<td>0.8430413</td>\n",
       "<td>0.8232156</td>\n",
       "<td>0.1390630</td>\n",
       "<td>0.6856340</td>\n",
       "<td>39.0693596</td>\n",
       "<td>71.4089956</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5016481</td>\n",
       "<td>1.1640300</td>\n",
       "<td>1.6040767</td>\n",
       "<td>0.5725051</td>\n",
       "<td>0.5547613</td>\n",
       "<td>0.7889334</td>\n",
       "<td>0.7695241</td>\n",
       "<td>0.1164043</td>\n",
       "<td>0.8020384</td>\n",
       "<td>16.4029983</td>\n",
       "<td>60.4076705</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000011</td>\n",
       "<td>0.3914881</td>\n",
       "<td>0.9061047</td>\n",
       "<td>1.4877469</td>\n",
       "<td>0.4456497</td>\n",
       "<td>0.4473204</td>\n",
       "<td>0.7317189</td>\n",
       "<td>0.7158230</td>\n",
       "<td>0.0906115</td>\n",
       "<td>0.8926499</td>\n",
       "<td>-9.3895288</td>\n",
       "<td>48.7746933</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999966</td>\n",
       "<td>0.2643055</td>\n",
       "<td>0.6125785</td>\n",
       "<td>1.3627280</td>\n",
       "<td>0.3012846</td>\n",
       "<td>0.3301080</td>\n",
       "<td>0.6702308</td>\n",
       "<td>0.6607231</td>\n",
       "<td>0.0612550</td>\n",
       "<td>0.9539049</td>\n",
       "<td>-38.7421527</td>\n",
       "<td>36.2727965</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999977</td>\n",
       "<td>0.1367315</td>\n",
       "<td>0.3346528</td>\n",
       "<td>1.2342167</td>\n",
       "<td>0.1645924</td>\n",
       "<td>0.1977272</td>\n",
       "<td>0.6070251</td>\n",
       "<td>0.6028478</td>\n",
       "<td>0.0334657</td>\n",
       "<td>0.9873706</td>\n",
       "<td>-66.5347184</td>\n",
       "<td>23.4216738</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999989</td>\n",
       "<td>0.0337288</td>\n",
       "<td>0.1134082</td>\n",
       "<td>1.1096809</td>\n",
       "<td>0.0557776</td>\n",
       "<td>0.0829282</td>\n",
       "<td>0.5457746</td>\n",
       "<td>0.5450782</td>\n",
       "<td>0.0113409</td>\n",
       "<td>0.9987115</td>\n",
       "<td>-88.6591814</td>\n",
       "<td>10.9680874</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0029924</td>\n",
       "<td>0.0128847</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0063371</td>\n",
       "<td>0.0131238</td>\n",
       "<td>0.4918302</td>\n",
       "<td>0.4918822</td>\n",
       "<td>0.0012885</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.7115344</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100024                   0.977705           2.02162    2.02162            0.994292         0.982796   0.994292                    0.982796            0.020221        0.020221                   102.162   102.162\n",
       "    2        0.0200048                   0.967772           2.01581    2.01872            0.991438         0.97249    0.992865                    0.977643            0.020163        0.040384                   101.581   101.872\n",
       "    3        0.0300015                   0.960133           2.01348    2.01697            0.990291         0.963816   0.992008                    0.973036            0.0201282       0.0605121                  101.348   101.697\n",
       "    4        0.0400039                   0.953601           2.01117    2.01552            0.989155         0.956836   0.991294                    0.968985            0.0201165       0.0806287                  101.117   101.552\n",
       "    5        0.0500006                   0.947329           1.99723    2.01186            0.982296         0.950491   0.989495                    0.965288            0.0199656       0.100594                   99.7225   101.186\n",
       "    6        0.100001                    0.917497           1.95359    1.98273            0.960836         0.93271    0.975166                    0.948999            0.0976807       0.198275                   95.3592   98.2728\n",
       "    7        0.150002                    0.879781           1.87953    1.94833            0.924412         0.899677   0.958248                    0.932558            0.0939778       0.292253                   87.9535   94.833\n",
       "    8        0.200002                    0.837241           1.78923    1.90855            0.879995         0.858935   0.938685                    0.914152            0.0894623       0.381715                   78.9226   90.8554\n",
       "    9        0.300003                    0.737254           1.64854    1.82188            0.810802         0.788493   0.896057                    0.872266            0.164856        0.546571                   64.8539   82.1883\n",
       "    10       0.399999                    0.612294           1.39069    1.71409            0.683985         0.676056   0.843041                    0.823216            0.139063        0.685634                   39.0694   71.409\n",
       "    11       0.5                         0.501648           1.16403    1.60408            0.572505         0.554761   0.788933                    0.769524            0.116404        0.802038                   16.403    60.4077\n",
       "    12       0.600001                    0.391488           0.906105   1.48775            0.44565          0.44732    0.731719                    0.715823            0.0906115       0.89265                    -9.38953  48.7747\n",
       "    13       0.699997                    0.264305           0.612578   1.36273            0.301285         0.330108   0.670231                    0.660723            0.061255        0.953905                   -38.7422  36.2728\n",
       "    14       0.799998                    0.136731           0.334653   1.23422            0.164592         0.197727   0.607025                    0.602848            0.0334657       0.987371                   -66.5347  23.4217\n",
       "    15       0.899999                    0.0337288          0.113408   1.10968            0.0557776        0.0829282  0.545775                    0.545078            0.0113409       0.998712                   -88.6592  10.9681\n",
       "    16       1                           0.00299243         0.0128847  1                  0.00633706       0.0131238  0.49183                     0.491882            0.00128848      1                          -98.7115  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.14274577098723212\n",
      "RMSE: 0.37781711314766053\n",
      "LogLoss: 0.4360396586479798\n",
      "Mean Per-Class Error: 0.20995014317543115\n",
      "AUC: 0.8774186628877368\n",
      "pr_auc: 0.8667499376145853\n",
      "Gini: 0.7548373257754737\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4241522872324221: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>63112.0</td>\n",
       "<td>25898.0</td>\n",
       "<td>0.291</td>\n",
       "<td> (25898.0/89010.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11793.0</td>\n",
       "<td>74355.0</td>\n",
       "<td>0.1369</td>\n",
       "<td> (11793.0/86148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>74905.0</td>\n",
       "<td>100253.0</td>\n",
       "<td>0.2152</td>\n",
       "<td> (37691.0/175158.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1       Error    Rate\n",
       "-----  -----  ------  -------  ------------------\n",
       "0      63112  25898   0.291    (25898.0/89010.0)\n",
       "1      11793  74355   0.1369   (11793.0/86148.0)\n",
       "Total  74905  100253  0.2152   (37691.0/175158.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4241523</td>\n",
       "<td>0.7977961</td>\n",
       "<td>230.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1978648</td>\n",
       "<td>0.8775257</td>\n",
       "<td>316.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6137050</td>\n",
       "<td>0.7978300</td>\n",
       "<td>154.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4840694</td>\n",
       "<td>0.7896756</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9885210</td>\n",
       "<td>0.9951691</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0062424</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9885210</td>\n",
       "<td>0.9999888</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4530389</td>\n",
       "<td>0.5805592</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5063477</td>\n",
       "<td>0.7884507</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4815399</td>\n",
       "<td>0.7900499</td>\n",
       "<td>207.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.424152     0.797796  230\n",
       "max f2                       0.197865     0.877526  316\n",
       "max f0point5                 0.613705     0.79783   154\n",
       "max accuracy                 0.484069     0.789676  206\n",
       "max precision                0.988521     0.995169  0\n",
       "max recall                   0.00624244   1         398\n",
       "max specificity              0.988521     0.999989  0\n",
       "max absolute_mcc             0.453039     0.580559  219\n",
       "max min_per_class_accuracy   0.506348     0.788451  197\n",
       "max mean_per_class_accuracy  0.48154      0.79005   207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 49.18 %, avg score: 49.19 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100024</td>\n",
       "<td>0.9762732</td>\n",
       "<td>2.0123326</td>\n",
       "<td>2.0123326</td>\n",
       "<td>0.9897260</td>\n",
       "<td>0.9816759</td>\n",
       "<td>0.9897260</td>\n",
       "<td>0.9816759</td>\n",
       "<td>0.0201282</td>\n",
       "<td>0.0201282</td>\n",
       "<td>101.2332631</td>\n",
       "<td>101.2332631</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200048</td>\n",
       "<td>0.9664814</td>\n",
       "<td>2.0100116</td>\n",
       "<td>2.0111721</td>\n",
       "<td>0.9885845</td>\n",
       "<td>0.9712869</td>\n",
       "<td>0.9891553</td>\n",
       "<td>0.9764814</td>\n",
       "<td>0.0201049</td>\n",
       "<td>0.0402331</td>\n",
       "<td>101.0011602</td>\n",
       "<td>101.1172116</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300015</td>\n",
       "<td>0.9590667</td>\n",
       "<td>1.9925807</td>\n",
       "<td>2.0049773</td>\n",
       "<td>0.9800114</td>\n",
       "<td>0.9625933</td>\n",
       "<td>0.9861085</td>\n",
       "<td>0.9718538</td>\n",
       "<td>0.0199192</td>\n",
       "<td>0.0601523</td>\n",
       "<td>99.2580683</td>\n",
       "<td>100.4977330</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400039</td>\n",
       "<td>0.9524291</td>\n",
       "<td>1.9868013</td>\n",
       "<td>2.0004327</td>\n",
       "<td>0.9771689</td>\n",
       "<td>0.9556459</td>\n",
       "<td>0.9838733</td>\n",
       "<td>0.9678012</td>\n",
       "<td>0.0198728</td>\n",
       "<td>0.0800251</td>\n",
       "<td>98.6801306</td>\n",
       "<td>100.0432676</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500006</td>\n",
       "<td>0.9464165</td>\n",
       "<td>1.9763242</td>\n",
       "<td>1.9956126</td>\n",
       "<td>0.9720160</td>\n",
       "<td>0.9493658</td>\n",
       "<td>0.9815026</td>\n",
       "<td>0.9641154</td>\n",
       "<td>0.0197567</td>\n",
       "<td>0.0997818</td>\n",
       "<td>97.6324197</td>\n",
       "<td>99.5612632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000011</td>\n",
       "<td>0.9165082</td>\n",
       "<td>1.9322341</td>\n",
       "<td>1.9639233</td>\n",
       "<td>0.9503311</td>\n",
       "<td>0.9315949</td>\n",
       "<td>0.9659169</td>\n",
       "<td>0.9478552</td>\n",
       "<td>0.0966128</td>\n",
       "<td>0.1963946</td>\n",
       "<td>93.2234055</td>\n",
       "<td>96.3923343</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500017</td>\n",
       "<td>0.8788684</td>\n",
       "<td>1.8502830</td>\n",
       "<td>1.9260432</td>\n",
       "<td>0.9100251</td>\n",
       "<td>0.8986896</td>\n",
       "<td>0.9472863</td>\n",
       "<td>0.9314666</td>\n",
       "<td>0.0925152</td>\n",
       "<td>0.2889098</td>\n",
       "<td>85.0283001</td>\n",
       "<td>92.6043229</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000023</td>\n",
       "<td>0.8347360</td>\n",
       "<td>1.7676355</td>\n",
       "<td>1.8864413</td>\n",
       "<td>0.8693766</td>\n",
       "<td>0.8570068</td>\n",
       "<td>0.9278089</td>\n",
       "<td>0.9128517</td>\n",
       "<td>0.0883828</td>\n",
       "<td>0.3772926</td>\n",
       "<td>76.7635479</td>\n",
       "<td>88.6441292</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000034</td>\n",
       "<td>0.7346722</td>\n",
       "<td>1.6254400</td>\n",
       "<td>1.7994408</td>\n",
       "<td>0.7994405</td>\n",
       "<td>0.7861476</td>\n",
       "<td>0.8850194</td>\n",
       "<td>0.8706170</td>\n",
       "<td>0.1625459</td>\n",
       "<td>0.5398384</td>\n",
       "<td>62.5439954</td>\n",
       "<td>79.9440846</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3999989</td>\n",
       "<td>0.6097599</td>\n",
       "<td>1.3862824</td>\n",
       "<td>1.6961557</td>\n",
       "<td>0.6818156</td>\n",
       "<td>0.6741783</td>\n",
       "<td>0.8342206</td>\n",
       "<td>0.8215094</td>\n",
       "<td>0.1386219</td>\n",
       "<td>0.6784603</td>\n",
       "<td>38.6282381</td>\n",
       "<td>69.6155652</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5008600</td>\n",
       "<td>1.1566010</td>\n",
       "<td>1.5882435</td>\n",
       "<td>0.5688513</td>\n",
       "<td>0.5533770</td>\n",
       "<td>0.7811462</td>\n",
       "<td>0.7678823</td>\n",
       "<td>0.1156614</td>\n",
       "<td>0.7941217</td>\n",
       "<td>15.6600992</td>\n",
       "<td>58.8243488</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000011</td>\n",
       "<td>0.3941432</td>\n",
       "<td>0.9083102</td>\n",
       "<td>1.4749202</td>\n",
       "<td>0.4467344</td>\n",
       "<td>0.4479039</td>\n",
       "<td>0.7254103</td>\n",
       "<td>0.7145521</td>\n",
       "<td>0.0908321</td>\n",
       "<td>0.8849538</td>\n",
       "<td>-9.1689807</td>\n",
       "<td>47.4920194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999966</td>\n",
       "<td>0.2661362</td>\n",
       "<td>0.6340541</td>\n",
       "<td>1.3548014</td>\n",
       "<td>0.3118470</td>\n",
       "<td>0.3325632</td>\n",
       "<td>0.6663323</td>\n",
       "<td>0.6599845</td>\n",
       "<td>0.0634025</td>\n",
       "<td>0.9483563</td>\n",
       "<td>-36.5945875</td>\n",
       "<td>35.4801368</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999977</td>\n",
       "<td>0.1393731</td>\n",
       "<td>0.3598417</td>\n",
       "<td>1.2304296</td>\n",
       "<td>0.1769810</td>\n",
       "<td>0.2002372</td>\n",
       "<td>0.6051625</td>\n",
       "<td>0.6025152</td>\n",
       "<td>0.0359846</td>\n",
       "<td>0.9843409</td>\n",
       "<td>-64.0158262</td>\n",
       "<td>23.0429639</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999989</td>\n",
       "<td>0.0354208</td>\n",
       "<td>0.1382489</td>\n",
       "<td>1.1090747</td>\n",
       "<td>0.0679950</td>\n",
       "<td>0.0849552</td>\n",
       "<td>0.5454765</td>\n",
       "<td>0.5450078</td>\n",
       "<td>0.0138250</td>\n",
       "<td>0.9981659</td>\n",
       "<td>-86.1751126</td>\n",
       "<td>10.9074681</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0020099</td>\n",
       "<td>0.0183403</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0090203</td>\n",
       "<td>0.0140550</td>\n",
       "<td>0.4918302</td>\n",
       "<td>0.4919119</td>\n",
       "<td>0.0018341</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.1659679</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100024                   0.976273           2.01233    2.01233            0.989726         0.981676   0.989726                    0.981676            0.0201282       0.0201282                  101.233   101.233\n",
       "    2        0.0200048                   0.966481           2.01001    2.01117            0.988584         0.971287   0.989155                    0.976481            0.0201049       0.0402331                  101.001   101.117\n",
       "    3        0.0300015                   0.959067           1.99258    2.00498            0.980011         0.962593   0.986108                    0.971854            0.0199192       0.0601523                  99.2581   100.498\n",
       "    4        0.0400039                   0.952429           1.9868     2.00043            0.977169         0.955646   0.983873                    0.967801            0.0198728       0.0800251                  98.6801   100.043\n",
       "    5        0.0500006                   0.946416           1.97632    1.99561            0.972016         0.949366   0.981503                    0.964115            0.0197567       0.0997818                  97.6324   99.5613\n",
       "    6        0.100001                    0.916508           1.93223    1.96392            0.950331         0.931595   0.965917                    0.947855            0.0966128       0.196395                   93.2234   96.3923\n",
       "    7        0.150002                    0.878868           1.85028    1.92604            0.910025         0.89869    0.947286                    0.931467            0.0925152       0.28891                    85.0283   92.6043\n",
       "    8        0.200002                    0.834736           1.76764    1.88644            0.869377         0.857007   0.927809                    0.912852            0.0883828       0.377293                   76.7635   88.6441\n",
       "    9        0.300003                    0.734672           1.62544    1.79944            0.799441         0.786148   0.885019                    0.870617            0.162546        0.539838                   62.544    79.9441\n",
       "    10       0.399999                    0.60976            1.38628    1.69616            0.681816         0.674178   0.834221                    0.821509            0.138622        0.67846                    38.6282   69.6156\n",
       "    11       0.5                         0.50086            1.1566     1.58824            0.568851         0.553377   0.781146                    0.767882            0.115661        0.794122                   15.6601   58.8243\n",
       "    12       0.600001                    0.394143           0.90831    1.47492            0.446734         0.447904   0.72541                     0.714552            0.0908321       0.884954                   -9.16898  47.492\n",
       "    13       0.699997                    0.266136           0.634054   1.3548             0.311847         0.332563   0.666332                    0.659984            0.0634025       0.948356                   -36.5946  35.4801\n",
       "    14       0.799998                    0.139373           0.359842   1.23043            0.176981         0.200237   0.605162                    0.602515            0.0359846       0.984341                   -64.0158  23.043\n",
       "    15       0.899999                    0.0354208          0.138249   1.10907            0.067995         0.0849552  0.545476                    0.545008            0.013825        0.998166                   -86.1751  10.9075\n",
       "    16       1                           0.00200994         0.0183403  1                  0.00902032       0.014055   0.49183                     0.491912            0.00183405      1                          -98.166   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.7830661</td>\n",
       "<td>0.0032539</td>\n",
       "<td>0.7864478</td>\n",
       "<td>0.7839656</td>\n",
       "<td>0.7743307</td>\n",
       "<td>0.7833688</td>\n",
       "<td>0.7872176</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8774689</td>\n",
       "<td>0.0009027</td>\n",
       "<td>0.8780848</td>\n",
       "<td>0.8772098</td>\n",
       "<td>0.8752478</td>\n",
       "<td>0.8776830</td>\n",
       "<td>0.8791192</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2169339</td>\n",
       "<td>0.0032539</td>\n",
       "<td>0.2135522</td>\n",
       "<td>0.2160344</td>\n",
       "<td>0.2256692</td>\n",
       "<td>0.2166312</td>\n",
       "<td>0.2127824</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>7600.0</td>\n",
       "<td>131.76115</td>\n",
       "<td>7507.0</td>\n",
       "<td>7580.0</td>\n",
       "<td>7958.0</td>\n",
       "<td>7534.0</td>\n",
       "<td>7421.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.7595552</td>\n",
       "<td>0.0050253</td>\n",
       "<td>0.7630531</td>\n",
       "<td>0.7621844</td>\n",
       "<td>0.7456005</td>\n",
       "<td>0.7614669</td>\n",
       "<td>0.7654711</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7983068</td>\n",
       "<td>0.0010096</td>\n",
       "<td>0.7987561</td>\n",
       "<td>0.7994709</td>\n",
       "<td>0.7956238</td>\n",
       "<td>0.7994997</td>\n",
       "<td>0.7981833</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.8413495</td>\n",
       "<td>0.0044821</td>\n",
       "<td>0.8379643</td>\n",
       "<td>0.8405933</td>\n",
       "<td>0.8528421</td>\n",
       "<td>0.8415315</td>\n",
       "<td>0.8338163</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.0100374</td>\n",
       "<td>0.0042276</td>\n",
       "<td>2.0150995</td>\n",
       "<td>2.0039814</td>\n",
       "<td>2.016216</td>\n",
       "<td>2.0017529</td>\n",
       "<td>2.013138</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.4360315</td>\n",
       "<td>0.0018154</td>\n",
       "<td>0.4356689</td>\n",
       "<td>0.4365759</td>\n",
       "<td>0.4397690</td>\n",
       "<td>0.4364041</td>\n",
       "<td>0.4317396</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3038000</td>\n",
       "<td>0.0147422</td>\n",
       "<td>0.2900423</td>\n",
       "<td>0.3007107</td>\n",
       "<td>0.3425328</td>\n",
       "<td>0.3036915</td>\n",
       "<td>0.2820225</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5773719</td>\n",
       "<td>0.0036461</td>\n",
       "<td>0.5821978</td>\n",
       "<td>0.5776324</td>\n",
       "<td>0.5680707</td>\n",
       "<td>0.5768155</td>\n",
       "<td>0.5821431</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7845036</td>\n",
       "<td>0.0030482</td>\n",
       "<td>0.7881358</td>\n",
       "<td>0.7848656</td>\n",
       "<td>0.7766285</td>\n",
       "<td>0.7842028</td>\n",
       "<td>0.7886854</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2154964</td>\n",
       "<td>0.0030482</td>\n",
       "<td>0.2118642</td>\n",
       "<td>0.2151344</td>\n",
       "<td>0.2233714</td>\n",
       "<td>0.2157972</td>\n",
       "<td>0.2113146</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1427428</td>\n",
       "<td>0.0005779</td>\n",
       "<td>0.1425119</td>\n",
       "<td>0.1428640</td>\n",
       "<td>0.1441381</td>\n",
       "<td>0.1425994</td>\n",
       "<td>0.1416006</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.7357904</td>\n",
       "<td>0.0073347</td>\n",
       "<td>0.7409728</td>\n",
       "<td>0.7392007</td>\n",
       "<td>0.7156057</td>\n",
       "<td>0.7380601</td>\n",
       "<td>0.7451130</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.4288609</td>\n",
       "<td>0.0023055</td>\n",
       "<td>0.4296863</td>\n",
       "<td>0.4284807</td>\n",
       "<td>0.4232332</td>\n",
       "<td>0.4295511</td>\n",
       "<td>0.4333533</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8728072</td>\n",
       "<td>0.0086971</td>\n",
       "<td>0.8663139</td>\n",
       "<td>0.8704418</td>\n",
       "<td>0.89579</td>\n",
       "<td>0.8720971</td>\n",
       "<td>0.8593933</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3778117</td>\n",
       "<td>0.0007643</td>\n",
       "<td>0.3775076</td>\n",
       "<td>0.3779736</td>\n",
       "<td>0.3796552</td>\n",
       "<td>0.3776233</td>\n",
       "<td>0.3762986</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6962</td>\n",
       "<td>0.0147422</td>\n",
       "<td>0.7099577</td>\n",
       "<td>0.6992893</td>\n",
       "<td>0.6574672</td>\n",
       "<td>0.6963086</td>\n",
       "<td>0.7179775</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.783066  0.00325388   0.786448      0.783966      0.774331      0.783369      0.787218\n",
       "auc                      0.877469  0.000902725  0.878085      0.87721       0.875248      0.877683      0.879119\n",
       "err                      0.216934  0.00325388   0.213552      0.216034      0.225669      0.216631      0.212782\n",
       "err_count                7600      131.761      7507          7580          7958          7534          7421\n",
       "f0point5                 0.759555  0.00502527   0.763053      0.762184      0.7456        0.761467      0.765471\n",
       "f1                       0.798307  0.00100964   0.798756      0.799471      0.795624      0.7995        0.798183\n",
       "f2                       0.841349  0.00448211   0.837964      0.840593      0.852842      0.841531      0.833816\n",
       "lift_top_group           2.01004   0.00422761   2.0151        2.00398       2.01622       2.00175       2.01314\n",
       "logloss                  0.436032  0.00181538   0.435669      0.436576      0.439769      0.436404      0.43174\n",
       "max_per_class_error      0.3038    0.0147422    0.290042      0.300711      0.342533      0.303691      0.282022\n",
       "mcc                      0.577372  0.00364615   0.582198      0.577632      0.568071      0.576816      0.582143\n",
       "mean_per_class_accuracy  0.784504  0.00304825   0.788136      0.784866      0.776629      0.784203      0.788685\n",
       "mean_per_class_error     0.215496  0.00304825   0.211864      0.215134      0.223371      0.215797      0.211315\n",
       "mse                      0.142743  0.00057792   0.142512      0.142864      0.144138      0.142599      0.141601\n",
       "precision                0.73579   0.00733467   0.740973      0.739201      0.715606      0.73806       0.745113\n",
       "r2                       0.428861  0.00230553   0.429686      0.428481      0.423233      0.429551      0.433353\n",
       "recall                   0.872807  0.00869714   0.866314      0.870442      0.89579       0.872097      0.859393\n",
       "rmse                     0.377812  0.000764345  0.377508      0.377974      0.379655      0.377623      0.376299\n",
       "specificity              0.6962    0.0147422    0.709958      0.699289      0.657467      0.696309      0.717978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:45:12</td>\n",
       "<td>49 min 10.086 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5081698</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:46:06</td>\n",
       "<td>50 min  4.280 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.4270245</td>\n",
       "<td>0.5526871</td>\n",
       "<td>0.8714396</td>\n",
       "<td>0.8616882</td>\n",
       "<td>2.0100116</td>\n",
       "<td>0.2247685</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:46:59</td>\n",
       "<td>50 min 57.128 sec</td>\n",
       "<td>200.0</td>\n",
       "<td>0.3972490</td>\n",
       "<td>0.4913000</td>\n",
       "<td>0.8745307</td>\n",
       "<td>0.8655151</td>\n",
       "<td>2.0158142</td>\n",
       "<td>0.2200756</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:47:54</td>\n",
       "<td>51 min 52.382 sec</td>\n",
       "<td>300.0</td>\n",
       "<td>0.3856947</td>\n",
       "<td>0.4627185</td>\n",
       "<td>0.8764400</td>\n",
       "<td>0.8669533</td>\n",
       "<td>2.0192957</td>\n",
       "<td>0.2164160</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:48:47</td>\n",
       "<td>52 min 45.473 sec</td>\n",
       "<td>400.0</td>\n",
       "<td>0.3809107</td>\n",
       "<td>0.4485616</td>\n",
       "<td>0.8777452</td>\n",
       "<td>0.8679981</td>\n",
       "<td>2.0192957</td>\n",
       "<td>0.2169641</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:49:41</td>\n",
       "<td>53 min 38.838 sec</td>\n",
       "<td>500.0</td>\n",
       "<td>0.3784605</td>\n",
       "<td>0.4406499</td>\n",
       "<td>0.8789008</td>\n",
       "<td>0.8697821</td>\n",
       "<td>2.0204562</td>\n",
       "<td>0.2157252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:50:35</td>\n",
       "<td>54 min 33.051 sec</td>\n",
       "<td>600.0</td>\n",
       "<td>0.3768100</td>\n",
       "<td>0.4355581</td>\n",
       "<td>0.8801161</td>\n",
       "<td>0.8709247</td>\n",
       "<td>2.0204562</td>\n",
       "<td>0.2140068</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:51:30</td>\n",
       "<td>55 min 27.952 sec</td>\n",
       "<td>700.0</td>\n",
       "<td>0.3755155</td>\n",
       "<td>0.4319546</td>\n",
       "<td>0.8813186</td>\n",
       "<td>0.8710628</td>\n",
       "<td>2.0204562</td>\n",
       "<td>0.2131504</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:52:26</td>\n",
       "<td>56 min 23.782 sec</td>\n",
       "<td>800.0</td>\n",
       "<td>0.3743740</td>\n",
       "<td>0.4291463</td>\n",
       "<td>0.8825444</td>\n",
       "<td>0.8727993</td>\n",
       "<td>2.0192957</td>\n",
       "<td>0.2125053</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:53:25</td>\n",
       "<td>57 min 23.477 sec</td>\n",
       "<td>900.0</td>\n",
       "<td>0.3731077</td>\n",
       "<td>0.4263142</td>\n",
       "<td>0.8839729</td>\n",
       "<td>0.8745666</td>\n",
       "<td>2.0181352</td>\n",
       "<td>0.2113406</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:54:24</td>\n",
       "<td>58 min 22.320 sec</td>\n",
       "<td>1000.0</td>\n",
       "<td>0.3718035</td>\n",
       "<td>0.4235577</td>\n",
       "<td>0.8854871</td>\n",
       "<td>0.8763070</td>\n",
       "<td>2.0192957</td>\n",
       "<td>0.2103301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-07-15 10:55:06</td>\n",
       "<td>59 min  3.843 sec</td>\n",
       "<td>1062.0</td>\n",
       "<td>0.3710939</td>\n",
       "<td>0.4220794</td>\n",
       "<td>0.8863087</td>\n",
       "<td>0.8771277</td>\n",
       "<td>2.0216167</td>\n",
       "<td>0.2086174</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration           number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  -----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2020-07-15 10:45:12  49 min 10.086 sec  0                  0.5              0.693147            0.5             0                  1                0.50817\n",
       "    2020-07-15 10:46:06  50 min  4.280 sec  100                0.427024         0.552687            0.87144         0.861688           2.01001          0.224768\n",
       "    2020-07-15 10:46:59  50 min 57.128 sec  200                0.397249         0.4913              0.874531        0.865515           2.01581          0.220076\n",
       "    2020-07-15 10:47:54  51 min 52.382 sec  300                0.385695         0.462719            0.87644         0.866953           2.0193           0.216416\n",
       "    2020-07-15 10:48:47  52 min 45.473 sec  400                0.380911         0.448562            0.877745        0.867998           2.0193           0.216964\n",
       "    2020-07-15 10:49:41  53 min 38.838 sec  500                0.378461         0.44065             0.878901        0.869782           2.02046          0.215725\n",
       "    2020-07-15 10:50:35  54 min 33.051 sec  600                0.37681          0.435558            0.880116        0.870925           2.02046          0.214007\n",
       "    2020-07-15 10:51:30  55 min 27.952 sec  700                0.375516         0.431955            0.881319        0.871063           2.02046          0.21315\n",
       "    2020-07-15 10:52:26  56 min 23.782 sec  800                0.374374         0.429146            0.882544        0.872799           2.0193           0.212505\n",
       "    2020-07-15 10:53:25  57 min 23.477 sec  900                0.373108         0.426314            0.883973        0.874567           2.01814          0.211341\n",
       "    2020-07-15 10:54:24  58 min 22.320 sec  1000               0.371804         0.423558            0.885487        0.876307           2.0193           0.21033\n",
       "    2020-07-15 10:55:06  59 min  3.843 sec  1062               0.371094         0.422079            0.886309        0.877128           2.02162          0.208617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>f10</td>\n",
       "<td>4053835.7500000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6988023</td></tr>\n",
       "<tr><td>e19</td>\n",
       "<td>446379.3437500</td>\n",
       "<td>0.1101128</td>\n",
       "<td>0.0769471</td></tr>\n",
       "<tr><td>e18</td>\n",
       "<td>121911.7187500</td>\n",
       "<td>0.0300732</td>\n",
       "<td>0.0210152</td></tr>\n",
       "<tr><td>f02</td>\n",
       "<td>121454.7187500</td>\n",
       "<td>0.0299604</td>\n",
       "<td>0.0209364</td></tr>\n",
       "<tr><td>f27.F</td>\n",
       "<td>93993.9062500</td>\n",
       "<td>0.0231864</td>\n",
       "<td>0.0162027</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>e21.P</td>\n",
       "<td>10.0393209</td>\n",
       "<td>0.0000025</td>\n",
       "<td>0.0000017</td></tr>\n",
       "<tr><td>e21.J</td>\n",
       "<td>8.7862110</td>\n",
       "<td>0.0000022</td>\n",
       "<td>0.0000015</td></tr>\n",
       "<tr><td>c05.A</td>\n",
       "<td>8.7393188</td>\n",
       "<td>0.0000022</td>\n",
       "<td>0.0000015</td></tr>\n",
       "<tr><td>e21.N</td>\n",
       "<td>5.7316165</td>\n",
       "<td>0.0000014</td>\n",
       "<td>0.0000010</td></tr>\n",
       "<tr><td>c07.A</td>\n",
       "<td>1.1391602</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0000002</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance       percentage\n",
       "----------  ---------------------  ----------------------  ----------------------\n",
       "f10         4053835.75             1.0                     0.6988022612978955\n",
       "e19         446379.34375           0.1101128341842661      0.07694709752588536\n",
       "e18         121911.71875           0.030073176682109036    0.021015203869868937\n",
       "f02         121454.71875           0.029960443944972364    0.020936425978235525\n",
       "f27.F       93993.90625            0.023186412091313762    0.016202717200794924\n",
       "---         ---                    ---                     ---\n",
       "e21.P       10.039320945739746     2.47649918863628e-06    1.7305832331214358e-06\n",
       "e21.J       8.786211013793945      2.167382093315928e-06   1.5145715079057367e-06\n",
       "c05.A       8.73931884765625       2.155814736119057e-06   1.506488212539323e-06\n",
       "e21.N       5.731616497039795      1.4138748707418141e-06  9.880189568666492e-07\n",
       "c07.A       1.13916015625          2.810079703525235e-07   1.963690051250754e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_hpropt_bst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Old model (not so important)\n",
    "I ran 40 models for 2 mins each, and was not expecting a better results since each model got only a time frame of 2 mins. But to my surprise this model yielded better Kaggle score of 0.867 compare to 0.865 of the above hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 1/40 [02:04<1:20:39, 124.10s/it, best loss: -0.8674585083914759]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/40 [04:08<1:18:42, 124.28s/it, best loss: -0.870175121415311] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/40 [06:14<1:16:54, 124.73s/it, best loss: -0.870175121415311]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4/40 [08:18<1:14:44, 124.56s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 5/40 [10:24<1:12:52, 124.93s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 6/40 [12:29<1:10:45, 124.87s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 7/40 [14:33<1:08:31, 124.58s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8/40 [16:38<1:06:37, 124.93s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 9/40 [18:43<1:04:25, 124.69s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [20:47<1:02:16, 124.55s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11/40 [22:51<1:00:13, 124.60s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12/40 [24:57<58:12, 124.72s/it, best loss: -0.871667523546091]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 13/40 [27:01<56:02, 124.55s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14/40 [29:05<53:54, 124.42s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15/40 [31:09<51:46, 124.27s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16/40 [33:13<49:39, 124.15s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 17/40 [35:17<47:37, 124.24s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 18/40 [37:21<45:31, 124.15s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 19/40 [39:25<43:26, 124.10s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 20/40 [41:29<41:22, 124.13s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 21/40 [43:34<39:22, 124.32s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 22/40 [45:39<37:20, 124.46s/it, best loss: -0.871667523546091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 23/40 [47:43<35:17, 124.56s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 24/40 [49:48<33:10, 124.44s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 25/40 [51:52<31:08, 124.54s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 26/40 [53:57<29:01, 124.42s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 27/40 [56:01<26:59, 124.56s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 28/40 [58:06<24:55, 124.61s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 29/40 [1:00:11<22:51, 124.66s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 30/40 [1:02:15<20:45, 124.53s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 31/40 [1:04:20<18:41, 124.61s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 32/40 [1:06:25<16:36, 124.59s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 33/40 [1:08:29<14:32, 124.64s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [1:10:34<12:27, 124.64s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 35/40 [1:12:38<10:22, 124.59s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 36/40 [1:14:43<08:17, 124.47s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 37/40 [1:16:47<06:13, 124.55s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 38/40 [1:18:51<04:08, 124.42s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 39/40 [1:20:56<02:04, 124.37s/it, best loss: -0.8718621667871277]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [1:23:00<00:00, 124.49s/it, best loss: -0.8719438506668313]\n",
      "{'learn_rate': 0.008933646880323847, 'max_depth': 8.0, 'min_rows': 10.0, 'ntrees': 2908.0, 'sample_rate': 0.5396549266120586}\n"
     ]
    }
   ],
   "source": [
    "# Optimisation - OLD\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "h2o.no_progress()\n",
    "best = hyperopt.fmin(hyperopt_objective,\n",
    "                     space=search_space,\n",
    "                     algo=hyperopt.tpe.suggest,\n",
    "                     max_evals=40,\n",
    "                     trials=trials,\n",
    "                     rstate=RandomState(2020)\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn_rate': 0.008933646880323847,\n",
       " 'max_depth': 8.0,\n",
       " 'min_rows': 10.0,\n",
       " 'ntrees': 2908.0,\n",
       " 'sample_rate': 0.5396549266120586}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
